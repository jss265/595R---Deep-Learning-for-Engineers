{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jss265/595R---Deep-Learning-for-Engineers/blob/main/HW%201%20-%20MLP/HW1_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "imXXOoBmlasu",
    "outputId": "43b8a821-9ab4-48f5-a084-ee648a21f87d"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(7, 24),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(24, 36),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(36, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    num_batches = len(dataloader)\n",
    "    train_loss = 0\n",
    "\n",
    "    for X, y in dataloader:\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        train_loss += loss.item() # .item() returns the number \n",
    "        \n",
    "    train_loss /= num_batches\n",
    "    print(f\"Train loss: {train_loss:>8f} \\n\")\n",
    "\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item() # .item() returns the number \n",
    "\n",
    "    test_loss /= num_batches # average test loss\n",
    "\n",
    "    print(f\"Test loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loaddata(batch_size):\n",
    "\n",
    "    data = np.genfromtxt(\n",
    "        'auto+mpg/auto-mpg.data',\n",
    "        usecols=range(8),     # ignore car name\n",
    "        missing_values='?',   # marks missing values\n",
    "        filling_values=np.nan # replaces ? with nan\n",
    "        )\n",
    "    data = data[~np.isnan(data).any(axis=1)] # removes rows with nan\n",
    "\n",
    "    features = torch.tensor(data[:, 1:], dtype=torch.float32)\n",
    "    targets = torch.tensor(data[:, :1].reshape(-1, 1), dtype=torch.float32)\n",
    "    print(features[0])\n",
    "    print(features.shape)\n",
    "\n",
    "    dataset = TensorDataset(features, targets)\n",
    "\n",
    "    train_ds, test_ds = random_split(dataset, [0.8, 0.2])\n",
    "\n",
    "    train_dataloader = DataLoader(train_ds, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_ds, batch_size=batch_size)\n",
    "\n",
    "    return train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8.0000e+00, 3.0700e+02, 1.3000e+02, 3.5040e+03, 1.2000e+01, 7.0000e+01,\n",
      "        1.0000e+00])\n",
      "torch.Size([392, 7])\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Train loss: 10930.851172 \n",
      "\n",
      "Test loss: 7531.416016 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train loss: 5264.523291 \n",
      "\n",
      "Test loss: 3022.668213 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train loss: 1987.461035 \n",
      "\n",
      "Test loss: 802.940887 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train loss: 521.361285 \n",
      "\n",
      "Test loss: 155.874077 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train loss: 201.234424 \n",
      "\n",
      "Test loss: 293.554214 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train loss: 336.115228 \n",
      "\n",
      "Test loss: 494.545319 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train loss: 422.642358 \n",
      "\n",
      "Test loss: 471.246246 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train loss: 352.595441 \n",
      "\n",
      "Test loss: 320.337921 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train loss: 241.116562 \n",
      "\n",
      "Test loss: 195.795830 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train loss: 179.594073 \n",
      "\n",
      "Test loss: 144.676056 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Train loss: 169.933749 \n",
      "\n",
      "Test loss: 137.011868 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Train loss: 176.627103 \n",
      "\n",
      "Test loss: 137.103699 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Train loss: 176.513800 \n",
      "\n",
      "Test loss: 133.032833 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Train loss: 168.553992 \n",
      "\n",
      "Test loss: 129.086712 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Train loss: 160.573312 \n",
      "\n",
      "Test loss: 129.477985 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Train loss: 157.139490 \n",
      "\n",
      "Test loss: 132.828426 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Train loss: 156.690741 \n",
      "\n",
      "Test loss: 134.678547 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Train loss: 156.243924 \n",
      "\n",
      "Test loss: 133.555599 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Train loss: 155.192511 \n",
      "\n",
      "Test loss: 130.824184 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Train loss: 154.122574 \n",
      "\n",
      "Test loss: 128.183907 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "Train loss: 153.379974 \n",
      "\n",
      "Test loss: 126.369045 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "Train loss: 152.800845 \n",
      "\n",
      "Test loss: 125.352833 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "Train loss: 152.163553 \n",
      "\n",
      "Test loss: 124.883385 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "Train loss: 151.440146 \n",
      "\n",
      "Test loss: 124.676426 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Train loss: 150.693130 \n",
      "\n",
      "Test loss: 124.439377 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "Train loss: 149.945636 \n",
      "\n",
      "Test loss: 123.961281 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "Train loss: 149.185184 \n",
      "\n",
      "Test loss: 123.203232 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "Train loss: 148.408838 \n",
      "\n",
      "Test loss: 122.272099 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "Train loss: 147.626312 \n",
      "\n",
      "Test loss: 121.310722 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "Train loss: 146.840735 \n",
      "\n",
      "Test loss: 120.411629 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "Train loss: 146.046005 \n",
      "\n",
      "Test loss: 119.594837 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "Train loss: 145.236383 \n",
      "\n",
      "Test loss: 118.829304 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "Train loss: 144.410672 \n",
      "\n",
      "Test loss: 118.065891 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "Train loss: 143.570251 \n",
      "\n",
      "Test loss: 117.266796 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "Train loss: 142.716592 \n",
      "\n",
      "Test loss: 116.420349 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "Train loss: 141.851279 \n",
      "\n",
      "Test loss: 115.537868 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "Train loss: 140.975290 \n",
      "\n",
      "Test loss: 114.638954 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "Train loss: 140.088727 \n",
      "\n",
      "Test loss: 113.738365 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "Train loss: 139.191043 \n",
      "\n",
      "Test loss: 112.839680 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "Train loss: 138.281689 \n",
      "\n",
      "Test loss: 111.938000 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "Train loss: 137.360559 \n",
      "\n",
      "Test loss: 111.025860 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "Train loss: 136.427898 \n",
      "\n",
      "Test loss: 110.098431 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "Train loss: 135.484160 \n",
      "\n",
      "Test loss: 109.155380 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "Train loss: 134.529756 \n",
      "\n",
      "Test loss: 108.199463 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "Train loss: 133.564981 \n",
      "\n",
      "Test loss: 107.233765 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "Train loss: 132.589900 \n",
      "\n",
      "Test loss: 106.259777 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "Train loss: 131.604570 \n",
      "\n",
      "Test loss: 105.277401 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "Train loss: 130.609076 \n",
      "\n",
      "Test loss: 104.285854 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "Train loss: 129.603596 \n",
      "\n",
      "Test loss: 103.284275 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Train loss: 128.588341 \n",
      "\n",
      "Test loss: 102.272598 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "Train loss: 127.563609 \n",
      "\n",
      "Test loss: 101.251324 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "Train loss: 126.529633 \n",
      "\n",
      "Test loss: 100.221241 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "Train loss: 125.486642 \n",
      "\n",
      "Test loss: 99.182846 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "Train loss: 124.434846 \n",
      "\n",
      "Test loss: 98.136353 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "Train loss: 123.374524 \n",
      "\n",
      "Test loss: 97.081879 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "Train loss: 122.305898 \n",
      "\n",
      "Test loss: 96.019550 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "Train loss: 121.229303 \n",
      "\n",
      "Test loss: 94.949680 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "Train loss: 120.145026 \n",
      "\n",
      "Test loss: 93.872746 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "Train loss: 119.053607 \n",
      "\n",
      "Test loss: 92.788700 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "Train loss: 117.955273 \n",
      "\n",
      "Test loss: 91.697845 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "Train loss: 116.850490 \n",
      "\n",
      "Test loss: 90.601536 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "Train loss: 115.739537 \n",
      "\n",
      "Test loss: 89.499638 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "Train loss: 114.623077 \n",
      "\n",
      "Test loss: 88.392311 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "Train loss: 113.501436 \n",
      "\n",
      "Test loss: 87.281048 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "Train loss: 112.374988 \n",
      "\n",
      "Test loss: 86.166634 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "Train loss: 111.244106 \n",
      "\n",
      "Test loss: 85.048950 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "Train loss: 110.109338 \n",
      "\n",
      "Test loss: 83.926598 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "Train loss: 108.971150 \n",
      "\n",
      "Test loss: 82.799408 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "Train loss: 107.830844 \n",
      "\n",
      "Test loss: 81.671999 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "Train loss: 106.688510 \n",
      "\n",
      "Test loss: 80.545938 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "Train loss: 105.544368 \n",
      "\n",
      "Test loss: 79.420471 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "Train loss: 104.398912 \n",
      "\n",
      "Test loss: 78.294092 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "Train loss: 103.252913 \n",
      "\n",
      "Test loss: 77.167082 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "Train loss: 102.107153 \n",
      "\n",
      "Test loss: 76.041019 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Train loss: 100.962370 \n",
      "\n",
      "Test loss: 74.917294 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "Train loss: 99.819064 \n",
      "\n",
      "Test loss: 73.796825 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "Train loss: 98.677800 \n",
      "\n",
      "Test loss: 72.677118 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "Train loss: 97.539749 \n",
      "\n",
      "Test loss: 71.561823 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "Train loss: 96.405663 \n",
      "\n",
      "Test loss: 70.453733 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "Train loss: 95.275906 \n",
      "\n",
      "Test loss: 69.352757 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "Train loss: 94.150992 \n",
      "\n",
      "Test loss: 68.257788 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "Train loss: 93.031795 \n",
      "\n",
      "Test loss: 67.168859 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "Train loss: 91.919246 \n",
      "\n",
      "Test loss: 66.087397 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "Train loss: 90.814163 \n",
      "\n",
      "Test loss: 65.015051 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "Train loss: 89.717220 \n",
      "\n",
      "Test loss: 63.952646 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "Train loss: 88.629033 \n",
      "\n",
      "Test loss: 62.900454 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "Train loss: 87.550276 \n",
      "\n",
      "Test loss: 61.857065 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "Train loss: 86.481981 \n",
      "\n",
      "Test loss: 60.825335 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "Train loss: 85.423604 \n",
      "\n",
      "Test loss: 59.804815 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "Train loss: 84.374620 \n",
      "\n",
      "Test loss: 58.792459 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "Train loss: 83.335272 \n",
      "\n",
      "Test loss: 57.793278 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "Train loss: 82.307056 \n",
      "\n",
      "Test loss: 56.813604 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "Train loss: 81.288976 \n",
      "\n",
      "Test loss: 55.846348 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "Train loss: 80.280481 \n",
      "\n",
      "Test loss: 54.888836 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "Train loss: 79.285728 \n",
      "\n",
      "Test loss: 53.950254 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "Train loss: 78.304326 \n",
      "\n",
      "Test loss: 53.029606 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "Train loss: 77.332898 \n",
      "\n",
      "Test loss: 52.120485 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "Train loss: 76.372815 \n",
      "\n",
      "Test loss: 51.225840 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "Train loss: 75.422775 \n",
      "\n",
      "Test loss: 50.347525 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Train loss: 74.486113 \n",
      "\n",
      "Test loss: 49.493584 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "Train loss: 73.562103 \n",
      "\n",
      "Test loss: 48.659536 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "Train loss: 72.650353 \n",
      "\n",
      "Test loss: 47.841467 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "Train loss: 71.749427 \n",
      "\n",
      "Test loss: 47.038636 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "Train loss: 70.861734 \n",
      "\n",
      "Test loss: 46.252301 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "Train loss: 69.983244 \n",
      "\n",
      "Test loss: 45.488832 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "Train loss: 69.119648 \n",
      "\n",
      "Test loss: 44.751666 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "Train loss: 68.268104 \n",
      "\n",
      "Test loss: 44.033678 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "Train loss: 67.429865 \n",
      "\n",
      "Test loss: 43.333508 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "Train loss: 66.609253 \n",
      "\n",
      "Test loss: 42.654955 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "Train loss: 65.808915 \n",
      "\n",
      "Test loss: 42.035447 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "Train loss: 65.023973 \n",
      "\n",
      "Test loss: 41.435881 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "Train loss: 64.241376 \n",
      "\n",
      "Test loss: 40.846780 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "Train loss: 63.475886 \n",
      "\n",
      "Test loss: 40.280091 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "Train loss: 62.722768 \n",
      "\n",
      "Test loss: 39.735144 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "Train loss: 61.975392 \n",
      "\n",
      "Test loss: 39.168928 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "Train loss: 61.238419 \n",
      "\n",
      "Test loss: 38.556723 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "Train loss: 60.511436 \n",
      "\n",
      "Test loss: 37.960649 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "Train loss: 59.789934 \n",
      "\n",
      "Test loss: 37.379906 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "Train loss: 59.086337 \n",
      "\n",
      "Test loss: 36.817932 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "Train loss: 58.401341 \n",
      "\n",
      "Test loss: 36.237782 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "Train loss: 57.721484 \n",
      "\n",
      "Test loss: 35.648195 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "Train loss: 57.063614 \n",
      "\n",
      "Test loss: 35.078549 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "Train loss: 56.414178 \n",
      "\n",
      "Test loss: 34.527325 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "Train loss: 55.770854 \n",
      "\n",
      "Test loss: 33.997926 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "Train loss: 55.149869 \n",
      "\n",
      "Test loss: 33.484940 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "Train loss: 54.535927 \n",
      "\n",
      "Test loss: 32.993267 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "Train loss: 53.930488 \n",
      "\n",
      "Test loss: 32.491274 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "Train loss: 53.352480 \n",
      "\n",
      "Test loss: 31.993171 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "Train loss: 52.787494 \n",
      "\n",
      "Test loss: 31.511101 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "Train loss: 52.235558 \n",
      "\n",
      "Test loss: 31.044532 \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "Train loss: 51.694756 \n",
      "\n",
      "Test loss: 30.588778 \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "Train loss: 51.164902 \n",
      "\n",
      "Test loss: 30.147061 \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "Train loss: 50.656319 \n",
      "\n",
      "Test loss: 29.730728 \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "Train loss: 50.154582 \n",
      "\n",
      "Test loss: 29.324512 \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "Train loss: 49.685753 \n",
      "\n",
      "Test loss: 28.931409 \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "Train loss: 49.216066 \n",
      "\n",
      "Test loss: 28.551267 \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "Train loss: 48.769108 \n",
      "\n",
      "Test loss: 28.190138 \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "Train loss: 48.340685 \n",
      "\n",
      "Test loss: 27.842025 \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "Train loss: 47.926163 \n",
      "\n",
      "Test loss: 27.508770 \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "Train loss: 47.519407 \n",
      "\n",
      "Test loss: 27.191473 \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "Train loss: 47.132513 \n",
      "\n",
      "Test loss: 26.887411 \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "Train loss: 46.763987 \n",
      "\n",
      "Test loss: 26.594258 \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "Train loss: 46.403886 \n",
      "\n",
      "Test loss: 26.310882 \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "Train loss: 46.054451 \n",
      "\n",
      "Test loss: 26.035151 \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "Train loss: 45.715600 \n",
      "\n",
      "Test loss: 25.764578 \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "Train loss: 45.387548 \n",
      "\n",
      "Test loss: 25.497598 \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "Train loss: 45.066927 \n",
      "\n",
      "Test loss: 25.240870 \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "Train loss: 44.750803 \n",
      "\n",
      "Test loss: 24.997254 \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "Train loss: 44.446660 \n",
      "\n",
      "Test loss: 24.760495 \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "Train loss: 44.151788 \n",
      "\n",
      "Test loss: 24.527650 \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "Train loss: 43.858320 \n",
      "\n",
      "Test loss: 24.301564 \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "Train loss: 43.572546 \n",
      "\n",
      "Test loss: 24.080931 \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "Train loss: 43.292281 \n",
      "\n",
      "Test loss: 23.864960 \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "Train loss: 43.017462 \n",
      "\n",
      "Test loss: 23.653471 \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "Train loss: 42.746152 \n",
      "\n",
      "Test loss: 23.447620 \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "Train loss: 42.487546 \n",
      "\n",
      "Test loss: 23.243854 \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "Train loss: 42.234065 \n",
      "\n",
      "Test loss: 23.051286 \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "Train loss: 41.981108 \n",
      "\n",
      "Test loss: 22.874367 \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "Train loss: 41.739906 \n",
      "\n",
      "Test loss: 22.702000 \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "Train loss: 41.506730 \n",
      "\n",
      "Test loss: 22.532590 \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "Train loss: 41.279987 \n",
      "\n",
      "Test loss: 22.375807 \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "Train loss: 41.050992 \n",
      "\n",
      "Test loss: 22.234398 \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "Train loss: 40.831212 \n",
      "\n",
      "Test loss: 22.099035 \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "Train loss: 40.617854 \n",
      "\n",
      "Test loss: 21.962364 \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "Train loss: 40.414845 \n",
      "\n",
      "Test loss: 21.819730 \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "Train loss: 40.204329 \n",
      "\n",
      "Test loss: 21.694253 \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "Train loss: 40.000506 \n",
      "\n",
      "Test loss: 21.574980 \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "Train loss: 39.802689 \n",
      "\n",
      "Test loss: 21.454759 \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "Train loss: 39.607745 \n",
      "\n",
      "Test loss: 21.331469 \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "Train loss: 39.409869 \n",
      "\n",
      "Test loss: 21.216422 \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "Train loss: 39.218160 \n",
      "\n",
      "Test loss: 21.100525 \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "Train loss: 39.035086 \n",
      "\n",
      "Test loss: 20.983082 \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "Train loss: 38.848103 \n",
      "\n",
      "Test loss: 20.880731 \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "Train loss: 38.649670 \n",
      "\n",
      "Test loss: 20.815645 \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "Train loss: 38.470812 \n",
      "\n",
      "Test loss: 20.720670 \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "Train loss: 38.286014 \n",
      "\n",
      "Test loss: 20.606646 \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "Train loss: 38.089418 \n",
      "\n",
      "Test loss: 20.518754 \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "Train loss: 37.906693 \n",
      "\n",
      "Test loss: 20.432462 \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "Train loss: 37.737775 \n",
      "\n",
      "Test loss: 20.324645 \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "Train loss: 37.559597 \n",
      "\n",
      "Test loss: 20.225855 \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "Train loss: 37.387003 \n",
      "\n",
      "Test loss: 20.130683 \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "Train loss: 37.220617 \n",
      "\n",
      "Test loss: 20.035861 \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "Train loss: 37.056639 \n",
      "\n",
      "Test loss: 19.944682 \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "Train loss: 36.893851 \n",
      "\n",
      "Test loss: 19.859464 \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "Train loss: 36.733715 \n",
      "\n",
      "Test loss: 19.776966 \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "Train loss: 36.573133 \n",
      "\n",
      "Test loss: 19.703436 \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "Train loss: 36.408991 \n",
      "\n",
      "Test loss: 19.639541 \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "Train loss: 36.245486 \n",
      "\n",
      "Test loss: 19.574118 \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "Train loss: 36.084838 \n",
      "\n",
      "Test loss: 19.507505 \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "Train loss: 35.919976 \n",
      "\n",
      "Test loss: 19.424829 \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "Train loss: 35.767689 \n",
      "\n",
      "Test loss: 19.340390 \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "Train loss: 35.608807 \n",
      "\n",
      "Test loss: 19.269609 \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "Train loss: 35.461639 \n",
      "\n",
      "Test loss: 19.189198 \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "Train loss: 35.316224 \n",
      "\n",
      "Test loss: 19.105237 \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "Train loss: 35.164525 \n",
      "\n",
      "Test loss: 19.035172 \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "Train loss: 35.018435 \n",
      "\n",
      "Test loss: 18.961917 \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "Train loss: 34.876264 \n",
      "\n",
      "Test loss: 18.880418 \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "Train loss: 34.736687 \n",
      "\n",
      "Test loss: 18.794670 \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "Train loss: 34.590272 \n",
      "\n",
      "Test loss: 18.726207 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "Train loss: 34.451824 \n",
      "\n",
      "Test loss: 18.655407 \n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "Train loss: 34.317794 \n",
      "\n",
      "Test loss: 18.576242 \n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "Train loss: 34.178756 \n",
      "\n",
      "Test loss: 18.503904 \n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "Train loss: 34.042960 \n",
      "\n",
      "Test loss: 18.431899 \n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "Train loss: 33.899857 \n",
      "\n",
      "Test loss: 18.372326 \n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "Train loss: 33.767400 \n",
      "\n",
      "Test loss: 18.295773 \n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "Train loss: 33.626134 \n",
      "\n",
      "Test loss: 18.226882 \n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "Train loss: 33.484821 \n",
      "\n",
      "Test loss: 18.162661 \n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "Train loss: 33.347301 \n",
      "\n",
      "Test loss: 18.096952 \n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "Train loss: 33.211214 \n",
      "\n",
      "Test loss: 18.030019 \n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "Train loss: 33.075397 \n",
      "\n",
      "Test loss: 17.963020 \n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "Train loss: 32.938800 \n",
      "\n",
      "Test loss: 17.898836 \n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "Train loss: 32.803274 \n",
      "\n",
      "Test loss: 17.835728 \n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "Train loss: 32.669818 \n",
      "\n",
      "Test loss: 17.770797 \n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "Train loss: 32.536261 \n",
      "\n",
      "Test loss: 17.707072 \n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "Train loss: 32.404132 \n",
      "\n",
      "Test loss: 17.647416 \n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "Train loss: 32.267799 \n",
      "\n",
      "Test loss: 17.602152 \n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "Train loss: 32.137851 \n",
      "\n",
      "Test loss: 17.552838 \n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "Train loss: 32.010376 \n",
      "\n",
      "Test loss: 17.495214 \n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "Train loss: 31.876184 \n",
      "\n",
      "Test loss: 17.449174 \n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "Train loss: 31.745339 \n",
      "\n",
      "Test loss: 17.404589 \n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "Train loss: 31.620327 \n",
      "\n",
      "Test loss: 17.349876 \n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "Train loss: 31.490963 \n",
      "\n",
      "Test loss: 17.300305 \n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "Train loss: 31.362585 \n",
      "\n",
      "Test loss: 17.253282 \n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "Train loss: 31.237558 \n",
      "\n",
      "Test loss: 17.202545 \n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "Train loss: 31.112246 \n",
      "\n",
      "Test loss: 17.151949 \n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "Train loss: 30.982724 \n",
      "\n",
      "Test loss: 17.112280 \n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "Train loss: 30.859983 \n",
      "\n",
      "Test loss: 17.064574 \n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "Train loss: 30.736948 \n",
      "\n",
      "Test loss: 17.015034 \n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "Train loss: 30.610987 \n",
      "\n",
      "Test loss: 16.972085 \n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "Train loss: 30.488291 \n",
      "\n",
      "Test loss: 16.927066 \n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "Train loss: 30.363174 \n",
      "\n",
      "Test loss: 16.894871 \n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "Train loss: 30.238570 \n",
      "\n",
      "Test loss: 16.856994 \n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "Train loss: 30.109190 \n",
      "\n",
      "Test loss: 16.790847 \n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "Train loss: 29.965586 \n",
      "\n",
      "Test loss: 16.728000 \n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "Train loss: 29.839367 \n",
      "\n",
      "Test loss: 16.652055 \n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "Train loss: 29.707190 \n",
      "\n",
      "Test loss: 16.591879 \n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "Train loss: 29.575015 \n",
      "\n",
      "Test loss: 16.541745 \n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "Train loss: 29.451546 \n",
      "\n",
      "Test loss: 16.476380 \n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "Train loss: 29.322139 \n",
      "\n",
      "Test loss: 16.411775 \n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "Train loss: 29.188495 \n",
      "\n",
      "Test loss: 16.355847 \n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "Train loss: 29.059591 \n",
      "\n",
      "Test loss: 16.290838 \n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "Train loss: 28.932621 \n",
      "\n",
      "Test loss: 16.219475 \n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "Train loss: 28.800922 \n",
      "\n",
      "Test loss: 16.155698 \n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "Train loss: 28.673858 \n",
      "\n",
      "Test loss: 16.090930 \n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "Train loss: 28.542247 \n",
      "\n",
      "Test loss: 16.028811 \n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "Train loss: 28.415993 \n",
      "\n",
      "Test loss: 15.959184 \n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "Train loss: 28.284704 \n",
      "\n",
      "Test loss: 15.892495 \n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "Train loss: 28.156889 \n",
      "\n",
      "Test loss: 15.825133 \n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "Train loss: 28.037134 \n",
      "\n",
      "Test loss: 15.758819 \n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "Train loss: 27.907840 \n",
      "\n",
      "Test loss: 15.707445 \n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "Train loss: 27.785755 \n",
      "\n",
      "Test loss: 15.650702 \n",
      "\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "Train loss: 27.664016 \n",
      "\n",
      "Test loss: 15.589896 \n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "Train loss: 27.535908 \n",
      "\n",
      "Test loss: 15.535257 \n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "Train loss: 27.407326 \n",
      "\n",
      "Test loss: 15.466292 \n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "Train loss: 27.283333 \n",
      "\n",
      "Test loss: 15.387903 \n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "Train loss: 27.156339 \n",
      "\n",
      "Test loss: 15.324461 \n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "Train loss: 27.031819 \n",
      "\n",
      "Test loss: 15.267091 \n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "Train loss: 26.909224 \n",
      "\n",
      "Test loss: 15.205444 \n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "Train loss: 26.786754 \n",
      "\n",
      "Test loss: 15.150443 \n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "Train loss: 26.662172 \n",
      "\n",
      "Test loss: 15.100590 \n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "Train loss: 26.542825 \n",
      "\n",
      "Test loss: 15.044742 \n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "Train loss: 26.419875 \n",
      "\n",
      "Test loss: 14.991310 \n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "Train loss: 26.298182 \n",
      "\n",
      "Test loss: 14.937902 \n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "Train loss: 26.178526 \n",
      "\n",
      "Test loss: 14.882932 \n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "Train loss: 26.058079 \n",
      "\n",
      "Test loss: 14.829917 \n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "Train loss: 25.939908 \n",
      "\n",
      "Test loss: 14.776044 \n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "Train loss: 25.822232 \n",
      "\n",
      "Test loss: 14.722519 \n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "Train loss: 25.704380 \n",
      "\n",
      "Test loss: 14.670621 \n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "Train loss: 25.587777 \n",
      "\n",
      "Test loss: 14.618632 \n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "Train loss: 25.471453 \n",
      "\n",
      "Test loss: 14.567013 \n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "Train loss: 25.355331 \n",
      "\n",
      "Test loss: 14.515681 \n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "Train loss: 25.239810 \n",
      "\n",
      "Test loss: 14.461881 \n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "Train loss: 25.125539 \n",
      "\n",
      "Test loss: 14.407109 \n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "Train loss: 25.011349 \n",
      "\n",
      "Test loss: 14.352961 \n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "Train loss: 24.897411 \n",
      "\n",
      "Test loss: 14.299799 \n",
      "\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "Train loss: 24.784632 \n",
      "\n",
      "Test loss: 14.244213 \n",
      "\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "Train loss: 24.667965 \n",
      "\n",
      "Test loss: 14.195328 \n",
      "\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "Train loss: 24.557744 \n",
      "\n",
      "Test loss: 14.141353 \n",
      "\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "Train loss: 24.446368 \n",
      "\n",
      "Test loss: 14.088271 \n",
      "\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "Train loss: 24.333170 \n",
      "\n",
      "Test loss: 14.039044 \n",
      "\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "Train loss: 24.226007 \n",
      "\n",
      "Test loss: 13.984469 \n",
      "\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "Train loss: 24.110471 \n",
      "\n",
      "Test loss: 13.939466 \n",
      "\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "Train loss: 24.002464 \n",
      "\n",
      "Test loss: 13.888330 \n",
      "\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "Train loss: 23.881291 \n",
      "\n",
      "Test loss: 13.839151 \n",
      "\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "Train loss: 23.773493 \n",
      "\n",
      "Test loss: 13.772374 \n",
      "\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "Train loss: 23.658139 \n",
      "\n",
      "Test loss: 13.719840 \n",
      "\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "Train loss: 23.543016 \n",
      "\n",
      "Test loss: 13.676616 \n",
      "\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "Train loss: 23.439716 \n",
      "\n",
      "Test loss: 13.623422 \n",
      "\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "Train loss: 23.325435 \n",
      "\n",
      "Test loss: 13.580148 \n",
      "\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "Train loss: 23.214513 \n",
      "\n",
      "Test loss: 13.535578 \n",
      "\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "Train loss: 23.106395 \n",
      "\n",
      "Test loss: 13.486845 \n",
      "\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "Train loss: 22.993835 \n",
      "\n",
      "Test loss: 13.442527 \n",
      "\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "Train loss: 22.885042 \n",
      "\n",
      "Test loss: 13.396893 \n",
      "\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "Train loss: 22.777784 \n",
      "\n",
      "Test loss: 13.348428 \n",
      "\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "Train loss: 22.668792 \n",
      "\n",
      "Test loss: 13.303954 \n",
      "\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "Train loss: 22.562991 \n",
      "\n",
      "Test loss: 13.258781 \n",
      "\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "Train loss: 22.457393 \n",
      "\n",
      "Test loss: 13.218913 \n",
      "\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "Train loss: 22.352813 \n",
      "\n",
      "Test loss: 13.177651 \n",
      "\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "Train loss: 22.249492 \n",
      "\n",
      "Test loss: 13.134008 \n",
      "\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "Train loss: 22.143783 \n",
      "\n",
      "Test loss: 13.093107 \n",
      "\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "Train loss: 22.044659 \n",
      "\n",
      "Test loss: 13.045470 \n",
      "\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "Train loss: 21.936676 \n",
      "\n",
      "Test loss: 13.005028 \n",
      "\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "Train loss: 21.838783 \n",
      "\n",
      "Test loss: 12.956042 \n",
      "\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "Train loss: 21.735675 \n",
      "\n",
      "Test loss: 12.916652 \n",
      "\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "Train loss: 21.635013 \n",
      "\n",
      "Test loss: 12.877612 \n",
      "\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "Train loss: 21.537353 \n",
      "\n",
      "Test loss: 12.834993 \n",
      "\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "Train loss: 21.435127 \n",
      "\n",
      "Test loss: 12.796096 \n",
      "\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "Train loss: 21.338532 \n",
      "\n",
      "Test loss: 12.751850 \n",
      "\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "Train loss: 21.235064 \n",
      "\n",
      "Test loss: 12.714589 \n",
      "\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "Train loss: 21.139348 \n",
      "\n",
      "Test loss: 12.670314 \n",
      "\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "Train loss: 21.043177 \n",
      "\n",
      "Test loss: 12.634193 \n",
      "\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "Train loss: 20.936347 \n",
      "\n",
      "Test loss: 12.594845 \n",
      "\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "Train loss: 20.844664 \n",
      "\n",
      "Test loss: 12.539366 \n",
      "\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "Train loss: 20.738247 \n",
      "\n",
      "Test loss: 12.503748 \n",
      "\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "Train loss: 20.645637 \n",
      "\n",
      "Test loss: 12.462350 \n",
      "\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "Train loss: 20.548409 \n",
      "\n",
      "Test loss: 12.425437 \n",
      "\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "Train loss: 20.450621 \n",
      "\n",
      "Test loss: 12.389510 \n",
      "\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "Train loss: 20.355416 \n",
      "\n",
      "Test loss: 12.350406 \n",
      "\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "Train loss: 20.256613 \n",
      "\n",
      "Test loss: 12.313986 \n",
      "\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "Train loss: 20.161022 \n",
      "\n",
      "Test loss: 12.275109 \n",
      "\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "Train loss: 20.065338 \n",
      "\n",
      "Test loss: 12.236869 \n",
      "\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "Train loss: 19.962704 \n",
      "\n",
      "Test loss: 12.201766 \n",
      "\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "Train loss: 19.870056 \n",
      "\n",
      "Test loss: 12.157476 \n",
      "\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "Train loss: 19.774271 \n",
      "\n",
      "Test loss: 12.117873 \n",
      "\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "Train loss: 19.678281 \n",
      "\n",
      "Test loss: 12.082636 \n",
      "\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "Train loss: 19.584431 \n",
      "\n",
      "Test loss: 12.046518 \n",
      "\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "Train loss: 19.490408 \n",
      "\n",
      "Test loss: 12.002709 \n",
      "\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "Train loss: 19.394875 \n",
      "\n",
      "Test loss: 11.959305 \n",
      "\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "Train loss: 19.302008 \n",
      "\n",
      "Test loss: 11.913863 \n",
      "\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "Train loss: 19.202480 \n",
      "\n",
      "Test loss: 11.863280 \n",
      "\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "Train loss: 19.109974 \n",
      "\n",
      "Test loss: 11.808948 \n",
      "\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "Train loss: 19.017339 \n",
      "\n",
      "Test loss: 11.761611 \n",
      "\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "Train loss: 18.923107 \n",
      "\n",
      "Test loss: 11.722111 \n",
      "\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "Train loss: 18.831981 \n",
      "\n",
      "Test loss: 11.682681 \n",
      "\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "Train loss: 18.740800 \n",
      "\n",
      "Test loss: 11.642393 \n",
      "\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "Train loss: 18.649060 \n",
      "\n",
      "Test loss: 11.601760 \n",
      "\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "Train loss: 18.556731 \n",
      "\n",
      "Test loss: 11.560350 \n",
      "\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "Train loss: 18.468237 \n",
      "\n",
      "Test loss: 11.516557 \n",
      "\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "Train loss: 18.377351 \n",
      "\n",
      "Test loss: 11.476269 \n",
      "\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "Train loss: 18.288226 \n",
      "\n",
      "Test loss: 11.434299 \n",
      "\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "Train loss: 18.200299 \n",
      "\n",
      "Test loss: 11.388750 \n",
      "\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "Train loss: 18.113412 \n",
      "\n",
      "Test loss: 11.345789 \n",
      "\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "Train loss: 18.024331 \n",
      "\n",
      "Test loss: 11.308590 \n",
      "\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "Train loss: 17.937210 \n",
      "\n",
      "Test loss: 11.272006 \n",
      "\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "Train loss: 17.852579 \n",
      "\n",
      "Test loss: 11.233393 \n",
      "\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "Train loss: 17.765431 \n",
      "\n",
      "Test loss: 11.196579 \n",
      "\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "Train loss: 17.681569 \n",
      "\n",
      "Test loss: 11.157697 \n",
      "\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "Train loss: 17.595867 \n",
      "\n",
      "Test loss: 11.121239 \n",
      "\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "Train loss: 17.514024 \n",
      "\n",
      "Test loss: 11.082529 \n",
      "\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "Train loss: 17.429755 \n",
      "\n",
      "Test loss: 11.047295 \n",
      "\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "Train loss: 17.341904 \n",
      "\n",
      "Test loss: 11.005765 \n",
      "\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "Train loss: 17.263152 \n",
      "\n",
      "Test loss: 10.954985 \n",
      "\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "Train loss: 17.175139 \n",
      "\n",
      "Test loss: 10.918222 \n",
      "\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "Train loss: 17.095562 \n",
      "\n",
      "Test loss: 10.882465 \n",
      "\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "Train loss: 17.016520 \n",
      "\n",
      "Test loss: 10.849349 \n",
      "\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "Train loss: 16.933308 \n",
      "\n",
      "Test loss: 10.819643 \n",
      "\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "Train loss: 16.855963 \n",
      "\n",
      "Test loss: 10.784697 \n",
      "\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "Train loss: 16.773398 \n",
      "\n",
      "Test loss: 10.752228 \n",
      "\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "Train loss: 16.696765 \n",
      "\n",
      "Test loss: 10.715857 \n",
      "\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "Train loss: 16.616996 \n",
      "\n",
      "Test loss: 10.683048 \n",
      "\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "Train loss: 16.541155 \n",
      "\n",
      "Test loss: 10.648956 \n",
      "\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "Train loss: 16.467143 \n",
      "\n",
      "Test loss: 10.617802 \n",
      "\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "Train loss: 16.387038 \n",
      "\n",
      "Test loss: 10.592092 \n",
      "\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "Train loss: 16.317402 \n",
      "\n",
      "Test loss: 10.557925 \n",
      "\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "Train loss: 16.239436 \n",
      "\n",
      "Test loss: 10.528616 \n",
      "\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "Train loss: 16.168041 \n",
      "\n",
      "Test loss: 10.494789 \n",
      "\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "Train loss: 16.094263 \n",
      "\n",
      "Test loss: 10.464890 \n",
      "\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "Train loss: 16.023341 \n",
      "\n",
      "Test loss: 10.435033 \n",
      "\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "Train loss: 15.954934 \n",
      "\n",
      "Test loss: 10.400044 \n",
      "\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "Train loss: 15.880909 \n",
      "\n",
      "Test loss: 10.370801 \n",
      "\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "Train loss: 15.811723 \n",
      "\n",
      "Test loss: 10.340592 \n",
      "\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "Train loss: 15.742973 \n",
      "\n",
      "Test loss: 10.312691 \n",
      "\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "Train loss: 15.673716 \n",
      "\n",
      "Test loss: 10.285319 \n",
      "\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "Train loss: 15.606980 \n",
      "\n",
      "Test loss: 10.256960 \n",
      "\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "Train loss: 15.538247 \n",
      "\n",
      "Test loss: 10.229765 \n",
      "\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "Train loss: 15.472576 \n",
      "\n",
      "Test loss: 10.201531 \n",
      "\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "Train loss: 15.405492 \n",
      "\n",
      "Test loss: 10.175210 \n",
      "\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "Train loss: 15.341122 \n",
      "\n",
      "Test loss: 10.147516 \n",
      "\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "Train loss: 15.277648 \n",
      "\n",
      "Test loss: 10.120652 \n",
      "\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "Train loss: 15.210576 \n",
      "\n",
      "Test loss: 10.096773 \n",
      "\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "Train loss: 15.150376 \n",
      "\n",
      "Test loss: 10.068618 \n",
      "\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "Train loss: 15.085162 \n",
      "\n",
      "Test loss: 10.044455 \n",
      "\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "Train loss: 15.026545 \n",
      "\n",
      "Test loss: 10.017059 \n",
      "\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "Train loss: 14.960869 \n",
      "\n",
      "Test loss: 9.995369 \n",
      "\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "Train loss: 14.903756 \n",
      "\n",
      "Test loss: 9.967865 \n",
      "\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "Train loss: 14.841091 \n",
      "\n",
      "Test loss: 9.945014 \n",
      "\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "Train loss: 14.783212 \n",
      "\n",
      "Test loss: 9.919469 \n",
      "\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "Train loss: 14.726793 \n",
      "\n",
      "Test loss: 9.900915 \n",
      "\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "Train loss: 14.667469 \n",
      "\n",
      "Test loss: 9.892602 \n",
      "\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "Train loss: 14.613560 \n",
      "\n",
      "Test loss: 9.874179 \n",
      "\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "Train loss: 14.554771 \n",
      "\n",
      "Test loss: 9.850832 \n",
      "\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "Train loss: 14.499543 \n",
      "\n",
      "Test loss: 9.821162 \n",
      "\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "Train loss: 14.444286 \n",
      "\n",
      "Test loss: 9.794307 \n",
      "\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "Train loss: 14.391129 \n",
      "\n",
      "Test loss: 9.770271 \n",
      "\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "Train loss: 14.339713 \n",
      "\n",
      "Test loss: 9.749875 \n",
      "\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "Train loss: 14.285027 \n",
      "\n",
      "Test loss: 9.731284 \n",
      "\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "Train loss: 14.235391 \n",
      "\n",
      "Test loss: 9.708605 \n",
      "\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "Train loss: 14.181211 \n",
      "\n",
      "Test loss: 9.687999 \n",
      "\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "Train loss: 14.133780 \n",
      "\n",
      "Test loss: 9.663006 \n",
      "\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "Train loss: 14.079082 \n",
      "\n",
      "Test loss: 9.645771 \n",
      "\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "Train loss: 14.031455 \n",
      "\n",
      "Test loss: 9.622878 \n",
      "\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "Train loss: 13.981296 \n",
      "\n",
      "Test loss: 9.601802 \n",
      "\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "Train loss: 13.931507 \n",
      "\n",
      "Test loss: 9.582223 \n",
      "\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "Train loss: 13.884606 \n",
      "\n",
      "Test loss: 9.560819 \n",
      "\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "Train loss: 13.835611 \n",
      "\n",
      "Test loss: 9.541669 \n",
      "\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "Train loss: 13.790402 \n",
      "\n",
      "Test loss: 9.520864 \n",
      "\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "Train loss: 13.741553 \n",
      "\n",
      "Test loss: 9.503211 \n",
      "\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "Train loss: 13.695331 \n",
      "\n",
      "Test loss: 9.483399 \n",
      "\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "Train loss: 13.649565 \n",
      "\n",
      "Test loss: 9.463492 \n",
      "\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "Train loss: 13.603858 \n",
      "\n",
      "Test loss: 9.444092 \n",
      "\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "Train loss: 13.559325 \n",
      "\n",
      "Test loss: 9.425145 \n",
      "\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "Train loss: 13.516020 \n",
      "\n",
      "Test loss: 9.406442 \n",
      "\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "Train loss: 13.471031 \n",
      "\n",
      "Test loss: 9.389337 \n",
      "\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "Train loss: 13.427143 \n",
      "\n",
      "Test loss: 9.370977 \n",
      "\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "Train loss: 13.384434 \n",
      "\n",
      "Test loss: 9.351869 \n",
      "\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "Train loss: 13.341632 \n",
      "\n",
      "Test loss: 9.333542 \n",
      "\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "Train loss: 13.299937 \n",
      "\n",
      "Test loss: 9.315706 \n",
      "\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "Train loss: 13.259524 \n",
      "\n",
      "Test loss: 9.298255 \n",
      "\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "Train loss: 13.217384 \n",
      "\n",
      "Test loss: 9.282310 \n",
      "\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "Train loss: 13.176400 \n",
      "\n",
      "Test loss: 9.265126 \n",
      "\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "Train loss: 13.136626 \n",
      "\n",
      "Test loss: 9.247083 \n",
      "\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "Train loss: 13.096424 \n",
      "\n",
      "Test loss: 9.229925 \n",
      "\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "Train loss: 13.058773 \n",
      "\n",
      "Test loss: 9.212738 \n",
      "\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "Train loss: 13.017369 \n",
      "\n",
      "Test loss: 9.198138 \n",
      "\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "Train loss: 12.981323 \n",
      "\n",
      "Test loss: 9.180346 \n",
      "\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "Train loss: 12.944506 \n",
      "\n",
      "Test loss: 9.170001 \n",
      "\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "Train loss: 12.903338 \n",
      "\n",
      "Test loss: 9.161783 \n",
      "\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "Train loss: 12.872189 \n",
      "\n",
      "Test loss: 9.140474 \n",
      "\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "Train loss: 12.829373 \n",
      "\n",
      "Test loss: 9.133056 \n",
      "\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "Train loss: 12.799058 \n",
      "\n",
      "Test loss: 9.115050 \n",
      "\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "Train loss: 12.759126 \n",
      "\n",
      "Test loss: 9.101790 \n",
      "\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "Train loss: 12.728135 \n",
      "\n",
      "Test loss: 9.082088 \n",
      "\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "Train loss: 12.690208 \n",
      "\n",
      "Test loss: 9.067813 \n",
      "\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "Train loss: 12.657676 \n",
      "\n",
      "Test loss: 9.050872 \n",
      "\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "Train loss: 12.623039 \n",
      "\n",
      "Test loss: 9.036184 \n",
      "\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "Train loss: 12.590405 \n",
      "\n",
      "Test loss: 9.020703 \n",
      "\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "Train loss: 12.557876 \n",
      "\n",
      "Test loss: 9.006135 \n",
      "\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "Train loss: 12.524555 \n",
      "\n",
      "Test loss: 8.991889 \n",
      "\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "Train loss: 12.491507 \n",
      "\n",
      "Test loss: 8.977055 \n",
      "\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "Train loss: 12.460037 \n",
      "\n",
      "Test loss: 8.961038 \n",
      "\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "Train loss: 12.427809 \n",
      "\n",
      "Test loss: 8.946212 \n",
      "\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "Train loss: 12.397987 \n",
      "\n",
      "Test loss: 8.931242 \n",
      "\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "Train loss: 12.364638 \n",
      "\n",
      "Test loss: 8.918280 \n",
      "\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "Train loss: 12.335886 \n",
      "\n",
      "Test loss: 8.903132 \n",
      "\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "Train loss: 12.305503 \n",
      "\n",
      "Test loss: 8.888962 \n",
      "\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "Train loss: 12.275475 \n",
      "\n",
      "Test loss: 8.875426 \n",
      "\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "Train loss: 12.244998 \n",
      "\n",
      "Test loss: 8.861790 \n",
      "\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "Train loss: 12.216547 \n",
      "\n",
      "Test loss: 8.847272 \n",
      "\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "Train loss: 12.188018 \n",
      "\n",
      "Test loss: 8.833542 \n",
      "\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "Train loss: 12.158999 \n",
      "\n",
      "Test loss: 8.820861 \n",
      "\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "Train loss: 12.130097 \n",
      "\n",
      "Test loss: 8.807726 \n",
      "\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "Train loss: 12.102700 \n",
      "\n",
      "Test loss: 8.793649 \n",
      "\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "Train loss: 12.074533 \n",
      "\n",
      "Test loss: 8.780237 \n",
      "\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "Train loss: 12.048272 \n",
      "\n",
      "Test loss: 8.767193 \n",
      "\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "Train loss: 12.020378 \n",
      "\n",
      "Test loss: 8.756010 \n",
      "\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "Train loss: 11.994423 \n",
      "\n",
      "Test loss: 8.743846 \n",
      "\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "Train loss: 11.967750 \n",
      "\n",
      "Test loss: 8.731702 \n",
      "\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "Train loss: 11.940606 \n",
      "\n",
      "Test loss: 8.719059 \n",
      "\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "Train loss: 11.915627 \n",
      "\n",
      "Test loss: 8.706542 \n",
      "\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "Train loss: 11.890977 \n",
      "\n",
      "Test loss: 8.694251 \n",
      "\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "Train loss: 11.864881 \n",
      "\n",
      "Test loss: 8.683357 \n",
      "\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "Train loss: 11.840699 \n",
      "\n",
      "Test loss: 8.671923 \n",
      "\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "Train loss: 11.814682 \n",
      "\n",
      "Test loss: 8.660354 \n",
      "\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "Train loss: 11.792334 \n",
      "\n",
      "Test loss: 8.647881 \n",
      "\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "Train loss: 11.766835 \n",
      "\n",
      "Test loss: 8.637020 \n",
      "\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "Train loss: 11.743235 \n",
      "\n",
      "Test loss: 8.626117 \n",
      "\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "Train loss: 11.720902 \n",
      "\n",
      "Test loss: 8.614247 \n",
      "\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "Train loss: 11.696685 \n",
      "\n",
      "Test loss: 8.603981 \n",
      "\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "Train loss: 11.673674 \n",
      "\n",
      "Test loss: 8.592722 \n",
      "\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "Train loss: 11.652113 \n",
      "\n",
      "Test loss: 8.581151 \n",
      "\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "Train loss: 11.628848 \n",
      "\n",
      "Test loss: 8.570591 \n",
      "\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "Train loss: 11.606453 \n",
      "\n",
      "Test loss: 8.559883 \n",
      "\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "Train loss: 11.585888 \n",
      "\n",
      "Test loss: 8.548309 \n",
      "\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "Train loss: 11.563197 \n",
      "\n",
      "Test loss: 8.538131 \n",
      "\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "Train loss: 11.541778 \n",
      "\n",
      "Test loss: 8.527081 \n",
      "\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "Train loss: 11.521544 \n",
      "\n",
      "Test loss: 8.515731 \n",
      "\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "Train loss: 11.499213 \n",
      "\n",
      "Test loss: 8.504190 \n",
      "\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "Train loss: 11.478779 \n",
      "\n",
      "Test loss: 8.492482 \n",
      "\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "Train loss: 11.458796 \n",
      "\n",
      "Test loss: 8.481331 \n",
      "\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "Train loss: 11.437620 \n",
      "\n",
      "Test loss: 8.470392 \n",
      "\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "Train loss: 11.418896 \n",
      "\n",
      "Test loss: 8.459802 \n",
      "\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "Train loss: 11.398321 \n",
      "\n",
      "Test loss: 8.450007 \n",
      "\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "Train loss: 11.379306 \n",
      "\n",
      "Test loss: 8.440591 \n",
      "\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "Train loss: 11.359080 \n",
      "\n",
      "Test loss: 8.430592 \n",
      "\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "Train loss: 11.341443 \n",
      "\n",
      "Test loss: 8.420890 \n",
      "\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "Train loss: 11.321804 \n",
      "\n",
      "Test loss: 8.411431 \n",
      "\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "Train loss: 11.303548 \n",
      "\n",
      "Test loss: 8.402821 \n",
      "\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "Train loss: 11.285231 \n",
      "\n",
      "Test loss: 8.392952 \n",
      "\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "Train loss: 11.266753 \n",
      "\n",
      "Test loss: 8.384105 \n",
      "\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "Train loss: 11.248386 \n",
      "\n",
      "Test loss: 8.374192 \n",
      "\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "Train loss: 11.231682 \n",
      "\n",
      "Test loss: 8.364932 \n",
      "\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "Train loss: 11.213586 \n",
      "\n",
      "Test loss: 8.355786 \n",
      "\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "Train loss: 11.196438 \n",
      "\n",
      "Test loss: 8.347409 \n",
      "\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "Train loss: 11.179435 \n",
      "\n",
      "Test loss: 8.337730 \n",
      "\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "Train loss: 11.161368 \n",
      "\n",
      "Test loss: 8.328919 \n",
      "\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "Train loss: 11.146377 \n",
      "\n",
      "Test loss: 8.318956 \n",
      "\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "Train loss: 11.128500 \n",
      "\n",
      "Test loss: 8.311113 \n",
      "\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "Train loss: 11.113392 \n",
      "\n",
      "Test loss: 8.301928 \n",
      "\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "Train loss: 11.096131 \n",
      "\n",
      "Test loss: 8.293558 \n",
      "\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "Train loss: 11.079907 \n",
      "\n",
      "Test loss: 8.285215 \n",
      "\n",
      "Epoch 501\n",
      "-------------------------------\n",
      "Train loss: 11.065641 \n",
      "\n",
      "Test loss: 8.275148 \n",
      "\n",
      "Epoch 502\n",
      "-------------------------------\n",
      "Train loss: 11.048413 \n",
      "\n",
      "Test loss: 8.267572 \n",
      "\n",
      "Epoch 503\n",
      "-------------------------------\n",
      "Train loss: 11.034047 \n",
      "\n",
      "Test loss: 8.259534 \n",
      "\n",
      "Epoch 504\n",
      "-------------------------------\n",
      "Train loss: 11.018531 \n",
      "\n",
      "Test loss: 8.250818 \n",
      "\n",
      "Epoch 505\n",
      "-------------------------------\n",
      "Train loss: 11.003322 \n",
      "\n",
      "Test loss: 8.242434 \n",
      "\n",
      "Epoch 506\n",
      "-------------------------------\n",
      "Train loss: 10.988269 \n",
      "\n",
      "Test loss: 8.233815 \n",
      "\n",
      "Epoch 507\n",
      "-------------------------------\n",
      "Train loss: 10.973448 \n",
      "\n",
      "Test loss: 8.226037 \n",
      "\n",
      "Epoch 508\n",
      "-------------------------------\n",
      "Train loss: 10.959319 \n",
      "\n",
      "Test loss: 8.217423 \n",
      "\n",
      "Epoch 509\n",
      "-------------------------------\n",
      "Train loss: 10.944466 \n",
      "\n",
      "Test loss: 8.209148 \n",
      "\n",
      "Epoch 510\n",
      "-------------------------------\n",
      "Train loss: 10.929336 \n",
      "\n",
      "Test loss: 8.201652 \n",
      "\n",
      "Epoch 511\n",
      "-------------------------------\n",
      "Train loss: 10.917000 \n",
      "\n",
      "Test loss: 8.192919 \n",
      "\n",
      "Epoch 512\n",
      "-------------------------------\n",
      "Train loss: 10.901869 \n",
      "\n",
      "Test loss: 8.184796 \n",
      "\n",
      "Epoch 513\n",
      "-------------------------------\n",
      "Train loss: 10.888214 \n",
      "\n",
      "Test loss: 8.177534 \n",
      "\n",
      "Epoch 514\n",
      "-------------------------------\n",
      "Train loss: 10.874793 \n",
      "\n",
      "Test loss: 8.169073 \n",
      "\n",
      "Epoch 515\n",
      "-------------------------------\n",
      "Train loss: 10.861117 \n",
      "\n",
      "Test loss: 8.161233 \n",
      "\n",
      "Epoch 516\n",
      "-------------------------------\n",
      "Train loss: 10.847916 \n",
      "\n",
      "Test loss: 8.153109 \n",
      "\n",
      "Epoch 517\n",
      "-------------------------------\n",
      "Train loss: 10.834476 \n",
      "\n",
      "Test loss: 8.145671 \n",
      "\n",
      "Epoch 518\n",
      "-------------------------------\n",
      "Train loss: 10.821566 \n",
      "\n",
      "Test loss: 8.138094 \n",
      "\n",
      "Epoch 519\n",
      "-------------------------------\n",
      "Train loss: 10.808482 \n",
      "\n",
      "Test loss: 8.130706 \n",
      "\n",
      "Epoch 520\n",
      "-------------------------------\n",
      "Train loss: 10.795813 \n",
      "\n",
      "Test loss: 8.122519 \n",
      "\n",
      "Epoch 521\n",
      "-------------------------------\n",
      "Train loss: 10.782584 \n",
      "\n",
      "Test loss: 8.115635 \n",
      "\n",
      "Epoch 522\n",
      "-------------------------------\n",
      "Train loss: 10.770866 \n",
      "\n",
      "Test loss: 8.107373 \n",
      "\n",
      "Epoch 523\n",
      "-------------------------------\n",
      "Train loss: 10.757781 \n",
      "\n",
      "Test loss: 8.100111 \n",
      "\n",
      "Epoch 524\n",
      "-------------------------------\n",
      "Train loss: 10.745918 \n",
      "\n",
      "Test loss: 8.092654 \n",
      "\n",
      "Epoch 525\n",
      "-------------------------------\n",
      "Train loss: 10.733577 \n",
      "\n",
      "Test loss: 8.085204 \n",
      "\n",
      "Epoch 526\n",
      "-------------------------------\n",
      "Train loss: 10.721559 \n",
      "\n",
      "Test loss: 8.078093 \n",
      "\n",
      "Epoch 527\n",
      "-------------------------------\n",
      "Train loss: 10.709810 \n",
      "\n",
      "Test loss: 8.069883 \n",
      "\n",
      "Epoch 528\n",
      "-------------------------------\n",
      "Train loss: 10.697386 \n",
      "\n",
      "Test loss: 8.063363 \n",
      "\n",
      "Epoch 529\n",
      "-------------------------------\n",
      "Train loss: 10.686020 \n",
      "\n",
      "Test loss: 8.055031 \n",
      "\n",
      "Epoch 530\n",
      "-------------------------------\n",
      "Train loss: 10.674800 \n",
      "\n",
      "Test loss: 8.048026 \n",
      "\n",
      "Epoch 531\n",
      "-------------------------------\n",
      "Train loss: 10.663377 \n",
      "\n",
      "Test loss: 8.040569 \n",
      "\n",
      "Epoch 532\n",
      "-------------------------------\n",
      "Train loss: 10.651792 \n",
      "\n",
      "Test loss: 8.034150 \n",
      "\n",
      "Epoch 533\n",
      "-------------------------------\n",
      "Train loss: 10.640987 \n",
      "\n",
      "Test loss: 8.026628 \n",
      "\n",
      "Epoch 534\n",
      "-------------------------------\n",
      "Train loss: 10.629495 \n",
      "\n",
      "Test loss: 8.019616 \n",
      "\n",
      "Epoch 535\n",
      "-------------------------------\n",
      "Train loss: 10.618770 \n",
      "\n",
      "Test loss: 8.012415 \n",
      "\n",
      "Epoch 536\n",
      "-------------------------------\n",
      "Train loss: 10.607784 \n",
      "\n",
      "Test loss: 8.005337 \n",
      "\n",
      "Epoch 537\n",
      "-------------------------------\n",
      "Train loss: 10.597057 \n",
      "\n",
      "Test loss: 7.998503 \n",
      "\n",
      "Epoch 538\n",
      "-------------------------------\n",
      "Train loss: 10.586449 \n",
      "\n",
      "Test loss: 7.991477 \n",
      "\n",
      "Epoch 539\n",
      "-------------------------------\n",
      "Train loss: 10.575820 \n",
      "\n",
      "Test loss: 7.984604 \n",
      "\n",
      "Epoch 540\n",
      "-------------------------------\n",
      "Train loss: 10.565446 \n",
      "\n",
      "Test loss: 7.977612 \n",
      "\n",
      "Epoch 541\n",
      "-------------------------------\n",
      "Train loss: 10.555048 \n",
      "\n",
      "Test loss: 7.970719 \n",
      "\n",
      "Epoch 542\n",
      "-------------------------------\n",
      "Train loss: 10.544831 \n",
      "\n",
      "Test loss: 7.963872 \n",
      "\n",
      "Epoch 543\n",
      "-------------------------------\n",
      "Train loss: 10.534682 \n",
      "\n",
      "Test loss: 7.957031 \n",
      "\n",
      "Epoch 544\n",
      "-------------------------------\n",
      "Train loss: 10.524618 \n",
      "\n",
      "Test loss: 7.950262 \n",
      "\n",
      "Epoch 545\n",
      "-------------------------------\n",
      "Train loss: 10.514679 \n",
      "\n",
      "Test loss: 7.943475 \n",
      "\n",
      "Epoch 546\n",
      "-------------------------------\n",
      "Train loss: 10.504814 \n",
      "\n",
      "Test loss: 7.936731 \n",
      "\n",
      "Epoch 547\n",
      "-------------------------------\n",
      "Train loss: 10.495049 \n",
      "\n",
      "Test loss: 7.930002 \n",
      "\n",
      "Epoch 548\n",
      "-------------------------------\n",
      "Train loss: 10.485371 \n",
      "\n",
      "Test loss: 7.923317 \n",
      "\n",
      "Epoch 549\n",
      "-------------------------------\n",
      "Train loss: 10.475791 \n",
      "\n",
      "Test loss: 7.916674 \n",
      "\n",
      "Epoch 550\n",
      "-------------------------------\n",
      "Train loss: 10.466273 \n",
      "\n",
      "Test loss: 7.910411 \n",
      "\n",
      "Epoch 551\n",
      "-------------------------------\n",
      "Train loss: 10.457089 \n",
      "\n",
      "Test loss: 7.903553 \n",
      "\n",
      "Epoch 552\n",
      "-------------------------------\n",
      "Train loss: 10.447383 \n",
      "\n",
      "Test loss: 7.897367 \n",
      "\n",
      "Epoch 553\n",
      "-------------------------------\n",
      "Train loss: 10.438444 \n",
      "\n",
      "Test loss: 7.890865 \n",
      "\n",
      "Epoch 554\n",
      "-------------------------------\n",
      "Train loss: 10.429152 \n",
      "\n",
      "Test loss: 7.884323 \n",
      "\n",
      "Epoch 555\n",
      "-------------------------------\n",
      "Train loss: 10.420065 \n",
      "\n",
      "Test loss: 7.878350 \n",
      "\n",
      "Epoch 556\n",
      "-------------------------------\n",
      "Train loss: 10.411392 \n",
      "\n",
      "Test loss: 7.871514 \n",
      "\n",
      "Epoch 557\n",
      "-------------------------------\n",
      "Train loss: 10.401995 \n",
      "\n",
      "Test loss: 7.865540 \n",
      "\n",
      "Epoch 558\n",
      "-------------------------------\n",
      "Train loss: 10.393536 \n",
      "\n",
      "Test loss: 7.859195 \n",
      "\n",
      "Epoch 559\n",
      "-------------------------------\n",
      "Train loss: 10.384634 \n",
      "\n",
      "Test loss: 7.852766 \n",
      "\n",
      "Epoch 560\n",
      "-------------------------------\n",
      "Train loss: 10.375928 \n",
      "\n",
      "Test loss: 7.846996 \n",
      "\n",
      "Epoch 561\n",
      "-------------------------------\n",
      "Train loss: 10.367676 \n",
      "\n",
      "Test loss: 7.840269 \n",
      "\n",
      "Epoch 562\n",
      "-------------------------------\n",
      "Train loss: 10.358649 \n",
      "\n",
      "Test loss: 7.834437 \n",
      "\n",
      "Epoch 563\n",
      "-------------------------------\n",
      "Train loss: 10.350574 \n",
      "\n",
      "Test loss: 7.828270 \n",
      "\n",
      "Epoch 564\n",
      "-------------------------------\n",
      "Train loss: 10.342068 \n",
      "\n",
      "Test loss: 7.821966 \n",
      "\n",
      "Epoch 565\n",
      "-------------------------------\n",
      "Train loss: 10.333710 \n",
      "\n",
      "Test loss: 7.816365 \n",
      "\n",
      "Epoch 566\n",
      "-------------------------------\n",
      "Train loss: 10.325850 \n",
      "\n",
      "Test loss: 7.809808 \n",
      "\n",
      "Epoch 567\n",
      "-------------------------------\n",
      "Train loss: 10.317173 \n",
      "\n",
      "Test loss: 7.804105 \n",
      "\n",
      "Epoch 568\n",
      "-------------------------------\n",
      "Train loss: 10.309447 \n",
      "\n",
      "Test loss: 7.798113 \n",
      "\n",
      "Epoch 569\n",
      "-------------------------------\n",
      "Train loss: 10.301326 \n",
      "\n",
      "Test loss: 7.791946 \n",
      "\n",
      "Epoch 570\n",
      "-------------------------------\n",
      "Train loss: 10.293274 \n",
      "\n",
      "Test loss: 7.786506 \n",
      "\n",
      "Epoch 571\n",
      "-------------------------------\n",
      "Train loss: 10.285777 \n",
      "\n",
      "Test loss: 7.780138 \n",
      "\n",
      "Epoch 572\n",
      "-------------------------------\n",
      "Train loss: 10.277454 \n",
      "\n",
      "Test loss: 7.774553 \n",
      "\n",
      "Epoch 573\n",
      "-------------------------------\n",
      "Train loss: 10.270030 \n",
      "\n",
      "Test loss: 7.768761 \n",
      "\n",
      "Epoch 574\n",
      "-------------------------------\n",
      "Train loss: 10.262280 \n",
      "\n",
      "Test loss: 7.762724 \n",
      "\n",
      "Epoch 575\n",
      "-------------------------------\n",
      "Train loss: 10.254548 \n",
      "\n",
      "Test loss: 7.757080 \n",
      "\n",
      "Epoch 576\n",
      "-------------------------------\n",
      "Train loss: 10.247164 \n",
      "\n",
      "Test loss: 7.751153 \n",
      "\n",
      "Epoch 577\n",
      "-------------------------------\n",
      "Train loss: 10.239521 \n",
      "\n",
      "Test loss: 7.745749 \n",
      "\n",
      "Epoch 578\n",
      "-------------------------------\n",
      "Train loss: 10.232364 \n",
      "\n",
      "Test loss: 7.739796 \n",
      "\n",
      "Epoch 579\n",
      "-------------------------------\n",
      "Train loss: 10.224624 \n",
      "\n",
      "Test loss: 7.734327 \n",
      "\n",
      "Epoch 580\n",
      "-------------------------------\n",
      "Train loss: 10.217516 \n",
      "\n",
      "Test loss: 7.728812 \n",
      "\n",
      "Epoch 581\n",
      "-------------------------------\n",
      "Train loss: 10.210250 \n",
      "\n",
      "Test loss: 7.723028 \n",
      "\n",
      "Epoch 582\n",
      "-------------------------------\n",
      "Train loss: 10.203211 \n",
      "\n",
      "Test loss: 7.717734 \n",
      "\n",
      "Epoch 583\n",
      "-------------------------------\n",
      "Train loss: 10.196435 \n",
      "\n",
      "Test loss: 7.710650 \n",
      "\n",
      "Epoch 584\n",
      "-------------------------------\n",
      "Train loss: 10.188396 \n",
      "\n",
      "Test loss: 7.706094 \n",
      "\n",
      "Epoch 585\n",
      "-------------------------------\n",
      "Train loss: 10.182214 \n",
      "\n",
      "Test loss: 7.700779 \n",
      "\n",
      "Epoch 586\n",
      "-------------------------------\n",
      "Train loss: 10.174857 \n",
      "\n",
      "Test loss: 7.695134 \n",
      "\n",
      "Epoch 587\n",
      "-------------------------------\n",
      "Train loss: 10.167940 \n",
      "\n",
      "Test loss: 7.690714 \n",
      "\n",
      "Epoch 588\n",
      "-------------------------------\n",
      "Train loss: 10.161768 \n",
      "\n",
      "Test loss: 7.683635 \n",
      "\n",
      "Epoch 589\n",
      "-------------------------------\n",
      "Train loss: 10.153683 \n",
      "\n",
      "Test loss: 7.679293 \n",
      "\n",
      "Epoch 590\n",
      "-------------------------------\n",
      "Train loss: 10.148166 \n",
      "\n",
      "Test loss: 7.674166 \n",
      "\n",
      "Epoch 591\n",
      "-------------------------------\n",
      "Train loss: 10.142080 \n",
      "\n",
      "Test loss: 7.677897 \n",
      "\n",
      "Epoch 592\n",
      "-------------------------------\n",
      "Train loss: 10.133593 \n",
      "\n",
      "Test loss: 7.690539 \n",
      "\n",
      "Epoch 593\n",
      "-------------------------------\n",
      "Train loss: 10.128764 \n",
      "\n",
      "Test loss: 7.687718 \n",
      "\n",
      "Epoch 594\n",
      "-------------------------------\n",
      "Train loss: 10.119658 \n",
      "\n",
      "Test loss: 7.673105 \n",
      "\n",
      "Epoch 595\n",
      "-------------------------------\n",
      "Train loss: 10.111289 \n",
      "\n",
      "Test loss: 7.660703 \n",
      "\n",
      "Epoch 596\n",
      "-------------------------------\n",
      "Train loss: 10.105269 \n",
      "\n",
      "Test loss: 7.654811 \n",
      "\n",
      "Epoch 597\n",
      "-------------------------------\n",
      "Train loss: 10.099162 \n",
      "\n",
      "Test loss: 7.652909 \n",
      "\n",
      "Epoch 598\n",
      "-------------------------------\n",
      "Train loss: 10.092836 \n",
      "\n",
      "Test loss: 7.650542 \n",
      "\n",
      "Epoch 599\n",
      "-------------------------------\n",
      "Train loss: 10.086192 \n",
      "\n",
      "Test loss: 7.643258 \n",
      "\n",
      "Epoch 600\n",
      "-------------------------------\n",
      "Train loss: 10.078263 \n",
      "\n",
      "Test loss: 7.636772 \n",
      "\n",
      "Epoch 601\n",
      "-------------------------------\n",
      "Train loss: 10.072670 \n",
      "\n",
      "Test loss: 7.630298 \n",
      "\n",
      "Epoch 602\n",
      "-------------------------------\n",
      "Train loss: 10.066119 \n",
      "\n",
      "Test loss: 7.623581 \n",
      "\n",
      "Epoch 603\n",
      "-------------------------------\n",
      "Train loss: 10.058787 \n",
      "\n",
      "Test loss: 7.620570 \n",
      "\n",
      "Epoch 604\n",
      "-------------------------------\n",
      "Train loss: 10.053826 \n",
      "\n",
      "Test loss: 7.615579 \n",
      "\n",
      "Epoch 605\n",
      "-------------------------------\n",
      "Train loss: 10.049622 \n",
      "\n",
      "Test loss: 7.622500 \n",
      "\n",
      "Epoch 606\n",
      "-------------------------------\n",
      "Train loss: 10.042924 \n",
      "\n",
      "Test loss: 7.624639 \n",
      "\n",
      "Epoch 607\n",
      "-------------------------------\n",
      "Train loss: 10.035510 \n",
      "\n",
      "Test loss: 7.610497 \n",
      "\n",
      "Epoch 608\n",
      "-------------------------------\n",
      "Train loss: 10.027115 \n",
      "\n",
      "Test loss: 7.595420 \n",
      "\n",
      "Epoch 609\n",
      "-------------------------------\n",
      "Train loss: 10.021141 \n",
      "\n",
      "Test loss: 7.589623 \n",
      "\n",
      "Epoch 610\n",
      "-------------------------------\n",
      "Train loss: 10.016582 \n",
      "\n",
      "Test loss: 7.587415 \n",
      "\n",
      "Epoch 611\n",
      "-------------------------------\n",
      "Train loss: 10.010124 \n",
      "\n",
      "Test loss: 7.589333 \n",
      "\n",
      "Epoch 612\n",
      "-------------------------------\n",
      "Train loss: 10.004504 \n",
      "\n",
      "Test loss: 7.586414 \n",
      "\n",
      "Epoch 613\n",
      "-------------------------------\n",
      "Train loss: 9.997344 \n",
      "\n",
      "Test loss: 7.579770 \n",
      "\n",
      "Epoch 614\n",
      "-------------------------------\n",
      "Train loss: 9.991186 \n",
      "\n",
      "Test loss: 7.570487 \n",
      "\n",
      "Epoch 615\n",
      "-------------------------------\n",
      "Train loss: 9.983352 \n",
      "\n",
      "Test loss: 7.558237 \n",
      "\n",
      "Epoch 616\n",
      "-------------------------------\n",
      "Train loss: 9.978032 \n",
      "\n",
      "Test loss: 7.548758 \n",
      "\n",
      "Epoch 617\n",
      "-------------------------------\n",
      "Train loss: 9.972468 \n",
      "\n",
      "Test loss: 7.544205 \n",
      "\n",
      "Epoch 618\n",
      "-------------------------------\n",
      "Train loss: 9.966550 \n",
      "\n",
      "Test loss: 7.544674 \n",
      "\n",
      "Epoch 619\n",
      "-------------------------------\n",
      "Train loss: 9.962215 \n",
      "\n",
      "Test loss: 7.541899 \n",
      "\n",
      "Epoch 620\n",
      "-------------------------------\n",
      "Train loss: 9.956124 \n",
      "\n",
      "Test loss: 7.534770 \n",
      "\n",
      "Epoch 621\n",
      "-------------------------------\n",
      "Train loss: 9.949445 \n",
      "\n",
      "Test loss: 7.529214 \n",
      "\n",
      "Epoch 622\n",
      "-------------------------------\n",
      "Train loss: 9.944130 \n",
      "\n",
      "Test loss: 7.521021 \n",
      "\n",
      "Epoch 623\n",
      "-------------------------------\n",
      "Train loss: 9.938419 \n",
      "\n",
      "Test loss: 7.514384 \n",
      "\n",
      "Epoch 624\n",
      "-------------------------------\n",
      "Train loss: 9.933241 \n",
      "\n",
      "Test loss: 7.510871 \n",
      "\n",
      "Epoch 625\n",
      "-------------------------------\n",
      "Train loss: 9.928374 \n",
      "\n",
      "Test loss: 7.507812 \n",
      "\n",
      "Epoch 626\n",
      "-------------------------------\n",
      "Train loss: 9.922996 \n",
      "\n",
      "Test loss: 7.503758 \n",
      "\n",
      "Epoch 627\n",
      "-------------------------------\n",
      "Train loss: 9.917593 \n",
      "\n",
      "Test loss: 7.499203 \n",
      "\n",
      "Epoch 628\n",
      "-------------------------------\n",
      "Train loss: 9.912632 \n",
      "\n",
      "Test loss: 7.493750 \n",
      "\n",
      "Epoch 629\n",
      "-------------------------------\n",
      "Train loss: 9.907078 \n",
      "\n",
      "Test loss: 7.489416 \n",
      "\n",
      "Epoch 630\n",
      "-------------------------------\n",
      "Train loss: 9.902202 \n",
      "\n",
      "Test loss: 7.485771 \n",
      "\n",
      "Epoch 631\n",
      "-------------------------------\n",
      "Train loss: 9.897334 \n",
      "\n",
      "Test loss: 7.481566 \n",
      "\n",
      "Epoch 632\n",
      "-------------------------------\n",
      "Train loss: 9.893426 \n",
      "\n",
      "Test loss: 7.488127 \n",
      "\n",
      "Epoch 633\n",
      "-------------------------------\n",
      "Train loss: 9.890002 \n",
      "\n",
      "Test loss: 7.488129 \n",
      "\n",
      "Epoch 634\n",
      "-------------------------------\n",
      "Train loss: 9.883196 \n",
      "\n",
      "Test loss: 7.480990 \n",
      "\n",
      "Epoch 635\n",
      "-------------------------------\n",
      "Train loss: 9.877176 \n",
      "\n",
      "Test loss: 7.472849 \n",
      "\n",
      "Epoch 636\n",
      "-------------------------------\n",
      "Train loss: 9.872727 \n",
      "\n",
      "Test loss: 7.465288 \n",
      "\n",
      "Epoch 637\n",
      "-------------------------------\n",
      "Train loss: 9.867129 \n",
      "\n",
      "Test loss: 7.463268 \n",
      "\n",
      "Epoch 638\n",
      "-------------------------------\n",
      "Train loss: 9.863571 \n",
      "\n",
      "Test loss: 7.461065 \n",
      "\n",
      "Epoch 639\n",
      "-------------------------------\n",
      "Train loss: 9.858336 \n",
      "\n",
      "Test loss: 7.456557 \n",
      "\n",
      "Epoch 640\n",
      "-------------------------------\n",
      "Train loss: 9.852742 \n",
      "\n",
      "Test loss: 7.451001 \n",
      "\n",
      "Epoch 641\n",
      "-------------------------------\n",
      "Train loss: 9.847463 \n",
      "\n",
      "Test loss: 7.447031 \n",
      "\n",
      "Epoch 642\n",
      "-------------------------------\n",
      "Train loss: 9.843628 \n",
      "\n",
      "Test loss: 7.442919 \n",
      "\n",
      "Epoch 643\n",
      "-------------------------------\n",
      "Train loss: 9.838799 \n",
      "\n",
      "Test loss: 7.437481 \n",
      "\n",
      "Epoch 644\n",
      "-------------------------------\n",
      "Train loss: 9.832863 \n",
      "\n",
      "Test loss: 7.435474 \n",
      "\n",
      "Epoch 645\n",
      "-------------------------------\n",
      "Train loss: 9.829862 \n",
      "\n",
      "Test loss: 7.430050 \n",
      "\n",
      "Epoch 646\n",
      "-------------------------------\n",
      "Train loss: 9.823881 \n",
      "\n",
      "Test loss: 7.425940 \n",
      "\n",
      "Epoch 647\n",
      "-------------------------------\n",
      "Train loss: 9.819822 \n",
      "\n",
      "Test loss: 7.422996 \n",
      "\n",
      "Epoch 648\n",
      "-------------------------------\n",
      "Train loss: 9.815474 \n",
      "\n",
      "Test loss: 7.418298 \n",
      "\n",
      "Epoch 649\n",
      "-------------------------------\n",
      "Train loss: 9.809906 \n",
      "\n",
      "Test loss: 7.415985 \n",
      "\n",
      "Epoch 650\n",
      "-------------------------------\n",
      "Train loss: 9.806117 \n",
      "\n",
      "Test loss: 7.413132 \n",
      "\n",
      "Epoch 651\n",
      "-------------------------------\n",
      "Train loss: 9.801715 \n",
      "\n",
      "Test loss: 7.408093 \n",
      "\n",
      "Epoch 652\n",
      "-------------------------------\n",
      "Train loss: 9.796231 \n",
      "\n",
      "Test loss: 7.404584 \n",
      "\n",
      "Epoch 653\n",
      "-------------------------------\n",
      "Train loss: 9.792416 \n",
      "\n",
      "Test loss: 7.400798 \n",
      "\n",
      "Epoch 654\n",
      "-------------------------------\n",
      "Train loss: 9.788208 \n",
      "\n",
      "Test loss: 7.396738 \n",
      "\n",
      "Epoch 655\n",
      "-------------------------------\n",
      "Train loss: 9.783916 \n",
      "\n",
      "Test loss: 7.392927 \n",
      "\n",
      "Epoch 656\n",
      "-------------------------------\n",
      "Train loss: 9.779558 \n",
      "\n",
      "Test loss: 7.389484 \n",
      "\n",
      "Epoch 657\n",
      "-------------------------------\n",
      "Train loss: 9.775311 \n",
      "\n",
      "Test loss: 7.385377 \n",
      "\n",
      "Epoch 658\n",
      "-------------------------------\n",
      "Train loss: 9.770563 \n",
      "\n",
      "Test loss: 7.381867 \n",
      "\n",
      "Epoch 659\n",
      "-------------------------------\n",
      "Train loss: 9.766604 \n",
      "\n",
      "Test loss: 7.379166 \n",
      "\n",
      "Epoch 660\n",
      "-------------------------------\n",
      "Train loss: 9.763072 \n",
      "\n",
      "Test loss: 7.375176 \n",
      "\n",
      "Epoch 661\n",
      "-------------------------------\n",
      "Train loss: 9.758450 \n",
      "\n",
      "Test loss: 7.370698 \n",
      "\n",
      "Epoch 662\n",
      "-------------------------------\n",
      "Train loss: 9.753736 \n",
      "\n",
      "Test loss: 7.367777 \n",
      "\n",
      "Epoch 663\n",
      "-------------------------------\n",
      "Train loss: 9.750257 \n",
      "\n",
      "Test loss: 7.365198 \n",
      "\n",
      "Epoch 664\n",
      "-------------------------------\n",
      "Train loss: 9.746699 \n",
      "\n",
      "Test loss: 7.361218 \n",
      "\n",
      "Epoch 665\n",
      "-------------------------------\n",
      "Train loss: 9.745056 \n",
      "\n",
      "Test loss: 7.376132 \n",
      "\n",
      "Epoch 666\n",
      "-------------------------------\n",
      "Train loss: 9.742026 \n",
      "\n",
      "Test loss: 7.385585 \n",
      "\n",
      "Epoch 667\n",
      "-------------------------------\n",
      "Train loss: 9.735842 \n",
      "\n",
      "Test loss: 7.379300 \n",
      "\n",
      "Epoch 668\n",
      "-------------------------------\n",
      "Train loss: 9.729895 \n",
      "\n",
      "Test loss: 7.361166 \n",
      "\n",
      "Epoch 669\n",
      "-------------------------------\n",
      "Train loss: 9.724299 \n",
      "\n",
      "Test loss: 7.355824 \n",
      "\n",
      "Epoch 670\n",
      "-------------------------------\n",
      "Train loss: 9.722131 \n",
      "\n",
      "Test loss: 7.358392 \n",
      "\n",
      "Epoch 671\n",
      "-------------------------------\n",
      "Train loss: 9.718810 \n",
      "\n",
      "Test loss: 7.353829 \n",
      "\n",
      "Epoch 672\n",
      "-------------------------------\n",
      "Train loss: 9.712693 \n",
      "\n",
      "Test loss: 7.347944 \n",
      "\n",
      "Epoch 673\n",
      "-------------------------------\n",
      "Train loss: 9.708477 \n",
      "\n",
      "Test loss: 7.343729 \n",
      "\n",
      "Epoch 674\n",
      "-------------------------------\n",
      "Train loss: 9.705282 \n",
      "\n",
      "Test loss: 7.339697 \n",
      "\n",
      "Epoch 675\n",
      "-------------------------------\n",
      "Train loss: 9.700962 \n",
      "\n",
      "Test loss: 7.336792 \n",
      "\n",
      "Epoch 676\n",
      "-------------------------------\n",
      "Train loss: 9.696882 \n",
      "\n",
      "Test loss: 7.334356 \n",
      "\n",
      "Epoch 677\n",
      "-------------------------------\n",
      "Train loss: 9.693172 \n",
      "\n",
      "Test loss: 7.330581 \n",
      "\n",
      "Epoch 678\n",
      "-------------------------------\n",
      "Train loss: 9.689004 \n",
      "\n",
      "Test loss: 7.326418 \n",
      "\n",
      "Epoch 679\n",
      "-------------------------------\n",
      "Train loss: 9.684955 \n",
      "\n",
      "Test loss: 7.323187 \n",
      "\n",
      "Epoch 680\n",
      "-------------------------------\n",
      "Train loss: 9.681335 \n",
      "\n",
      "Test loss: 7.320237 \n",
      "\n",
      "Epoch 681\n",
      "-------------------------------\n",
      "Train loss: 9.677544 \n",
      "\n",
      "Test loss: 7.317145 \n",
      "\n",
      "Epoch 682\n",
      "-------------------------------\n",
      "Train loss: 9.673621 \n",
      "\n",
      "Test loss: 7.314113 \n",
      "\n",
      "Epoch 683\n",
      "-------------------------------\n",
      "Train loss: 9.669882 \n",
      "\n",
      "Test loss: 7.311027 \n",
      "\n",
      "Epoch 684\n",
      "-------------------------------\n",
      "Train loss: 9.666174 \n",
      "\n",
      "Test loss: 7.307940 \n",
      "\n",
      "Epoch 685\n",
      "-------------------------------\n",
      "Train loss: 9.662437 \n",
      "\n",
      "Test loss: 7.305032 \n",
      "\n",
      "Epoch 686\n",
      "-------------------------------\n",
      "Train loss: 9.658770 \n",
      "\n",
      "Test loss: 7.302285 \n",
      "\n",
      "Epoch 687\n",
      "-------------------------------\n",
      "Train loss: 9.655355 \n",
      "\n",
      "Test loss: 7.299620 \n",
      "\n",
      "Epoch 688\n",
      "-------------------------------\n",
      "Train loss: 9.652133 \n",
      "\n",
      "Test loss: 7.294975 \n",
      "\n",
      "Epoch 689\n",
      "-------------------------------\n",
      "Train loss: 9.647628 \n",
      "\n",
      "Test loss: 7.291943 \n",
      "\n",
      "Epoch 690\n",
      "-------------------------------\n",
      "Train loss: 9.644332 \n",
      "\n",
      "Test loss: 7.289933 \n",
      "\n",
      "Epoch 691\n",
      "-------------------------------\n",
      "Train loss: 9.641259 \n",
      "\n",
      "Test loss: 7.287001 \n",
      "\n",
      "Epoch 692\n",
      "-------------------------------\n",
      "Train loss: 9.637410 \n",
      "\n",
      "Test loss: 7.284207 \n",
      "\n",
      "Epoch 693\n",
      "-------------------------------\n",
      "Train loss: 9.634050 \n",
      "\n",
      "Test loss: 7.282145 \n",
      "\n",
      "Epoch 694\n",
      "-------------------------------\n",
      "Train loss: 9.631236 \n",
      "\n",
      "Test loss: 7.277882 \n",
      "\n",
      "Epoch 695\n",
      "-------------------------------\n",
      "Train loss: 9.626866 \n",
      "\n",
      "Test loss: 7.274913 \n",
      "\n",
      "Epoch 696\n",
      "-------------------------------\n",
      "Train loss: 9.623539 \n",
      "\n",
      "Test loss: 7.273344 \n",
      "\n",
      "Epoch 697\n",
      "-------------------------------\n",
      "Train loss: 9.620941 \n",
      "\n",
      "Test loss: 7.271007 \n",
      "\n",
      "Epoch 698\n",
      "-------------------------------\n",
      "Train loss: 9.617752 \n",
      "\n",
      "Test loss: 7.266501 \n",
      "\n",
      "Epoch 699\n",
      "-------------------------------\n",
      "Train loss: 9.613309 \n",
      "\n",
      "Test loss: 7.264139 \n",
      "\n",
      "Epoch 700\n",
      "-------------------------------\n",
      "Train loss: 9.610415 \n",
      "\n",
      "Test loss: 7.262794 \n",
      "\n",
      "Epoch 701\n",
      "-------------------------------\n",
      "Train loss: 9.607880 \n",
      "\n",
      "Test loss: 7.260368 \n",
      "\n",
      "Epoch 702\n",
      "-------------------------------\n",
      "Train loss: 9.604608 \n",
      "\n",
      "Test loss: 7.256157 \n",
      "\n",
      "Epoch 703\n",
      "-------------------------------\n",
      "Train loss: 9.600358 \n",
      "\n",
      "Test loss: 7.254071 \n",
      "\n",
      "Epoch 704\n",
      "-------------------------------\n",
      "Train loss: 9.597780 \n",
      "\n",
      "Test loss: 7.252969 \n",
      "\n",
      "Epoch 705\n",
      "-------------------------------\n",
      "Train loss: 9.595517 \n",
      "\n",
      "Test loss: 7.248767 \n",
      "\n",
      "Epoch 706\n",
      "-------------------------------\n",
      "Train loss: 9.591051 \n",
      "\n",
      "Test loss: 7.246047 \n",
      "\n",
      "Epoch 707\n",
      "-------------------------------\n",
      "Train loss: 9.587878 \n",
      "\n",
      "Test loss: 7.245273 \n",
      "\n",
      "Epoch 708\n",
      "-------------------------------\n",
      "Train loss: 9.585816 \n",
      "\n",
      "Test loss: 7.243528 \n",
      "\n",
      "Epoch 709\n",
      "-------------------------------\n",
      "Train loss: 9.583071 \n",
      "\n",
      "Test loss: 7.239441 \n",
      "\n",
      "Epoch 710\n",
      "-------------------------------\n",
      "Train loss: 9.579199 \n",
      "\n",
      "Test loss: 7.236483 \n",
      "\n",
      "Epoch 711\n",
      "-------------------------------\n",
      "Train loss: 9.576203 \n",
      "\n",
      "Test loss: 7.233917 \n",
      "\n",
      "Epoch 712\n",
      "-------------------------------\n",
      "Train loss: 9.573259 \n",
      "\n",
      "Test loss: 7.232407 \n",
      "\n",
      "Epoch 713\n",
      "-------------------------------\n",
      "Train loss: 9.570930 \n",
      "\n",
      "Test loss: 7.230077 \n",
      "\n",
      "Epoch 714\n",
      "-------------------------------\n",
      "Train loss: 9.567785 \n",
      "\n",
      "Test loss: 7.227647 \n",
      "\n",
      "Epoch 715\n",
      "-------------------------------\n",
      "Train loss: 9.564466 \n",
      "\n",
      "Test loss: 7.225454 \n",
      "\n",
      "Epoch 716\n",
      "-------------------------------\n",
      "Train loss: 9.561362 \n",
      "\n",
      "Test loss: 7.228078 \n",
      "\n",
      "Epoch 717\n",
      "-------------------------------\n",
      "Train loss: 9.558066 \n",
      "\n",
      "Test loss: 7.267323 \n",
      "\n",
      "Epoch 718\n",
      "-------------------------------\n",
      "Train loss: 9.562283 \n",
      "\n",
      "Test loss: 7.279047 \n",
      "\n",
      "Epoch 719\n",
      "-------------------------------\n",
      "Train loss: 9.556742 \n",
      "\n",
      "Test loss: 7.251674 \n",
      "\n",
      "Epoch 720\n",
      "-------------------------------\n",
      "Train loss: 9.544416 \n",
      "\n",
      "Test loss: 7.233512 \n",
      "\n",
      "Epoch 721\n",
      "-------------------------------\n",
      "Train loss: 9.542516 \n",
      "\n",
      "Test loss: 7.238786 \n",
      "\n",
      "Epoch 722\n",
      "-------------------------------\n",
      "Train loss: 9.545102 \n",
      "\n",
      "Test loss: 7.245808 \n",
      "\n",
      "Epoch 723\n",
      "-------------------------------\n",
      "Train loss: 9.541792 \n",
      "\n",
      "Test loss: 7.244024 \n",
      "\n",
      "Epoch 724\n",
      "-------------------------------\n",
      "Train loss: 9.535823 \n",
      "\n",
      "Test loss: 7.237701 \n",
      "\n",
      "Epoch 725\n",
      "-------------------------------\n",
      "Train loss: 9.531755 \n",
      "\n",
      "Test loss: 7.232774 \n",
      "\n",
      "Epoch 726\n",
      "-------------------------------\n",
      "Train loss: 9.529616 \n",
      "\n",
      "Test loss: 7.229978 \n",
      "\n",
      "Epoch 727\n",
      "-------------------------------\n",
      "Train loss: 9.526938 \n",
      "\n",
      "Test loss: 7.229716 \n",
      "\n",
      "Epoch 728\n",
      "-------------------------------\n",
      "Train loss: 9.528855 \n",
      "\n",
      "Test loss: 7.271691 \n",
      "\n",
      "Epoch 729\n",
      "-------------------------------\n",
      "Train loss: 9.528877 \n",
      "\n",
      "Test loss: 7.291374 \n",
      "\n",
      "Epoch 730\n",
      "-------------------------------\n",
      "Train loss: 9.520730 \n",
      "\n",
      "Test loss: 7.272902 \n",
      "\n",
      "Epoch 731\n",
      "-------------------------------\n",
      "Train loss: 9.510212 \n",
      "\n",
      "Test loss: 7.248544 \n",
      "\n",
      "Epoch 732\n",
      "-------------------------------\n",
      "Train loss: 9.505251 \n",
      "\n",
      "Test loss: 7.245172 \n",
      "\n",
      "Epoch 733\n",
      "-------------------------------\n",
      "Train loss: 9.505309 \n",
      "\n",
      "Test loss: 7.253908 \n",
      "\n",
      "Epoch 734\n",
      "-------------------------------\n",
      "Train loss: 9.503017 \n",
      "\n",
      "Test loss: 7.257087 \n",
      "\n",
      "Epoch 735\n",
      "-------------------------------\n",
      "Train loss: 9.497155 \n",
      "\n",
      "Test loss: 7.251811 \n",
      "\n",
      "Epoch 736\n",
      "-------------------------------\n",
      "Train loss: 9.491563 \n",
      "\n",
      "Test loss: 7.245109 \n",
      "\n",
      "Epoch 737\n",
      "-------------------------------\n",
      "Train loss: 9.487889 \n",
      "\n",
      "Test loss: 7.242121 \n",
      "\n",
      "Epoch 738\n",
      "-------------------------------\n",
      "Train loss: 9.484844 \n",
      "\n",
      "Test loss: 7.241312 \n",
      "\n",
      "Epoch 739\n",
      "-------------------------------\n",
      "Train loss: 9.480776 \n",
      "\n",
      "Test loss: 7.241082 \n",
      "\n",
      "Epoch 740\n",
      "-------------------------------\n",
      "Train loss: 9.477357 \n",
      "\n",
      "Test loss: 7.245481 \n",
      "\n",
      "Epoch 741\n",
      "-------------------------------\n",
      "Train loss: 9.474557 \n",
      "\n",
      "Test loss: 7.248168 \n",
      "\n",
      "Epoch 742\n",
      "-------------------------------\n",
      "Train loss: 9.470588 \n",
      "\n",
      "Test loss: 7.244886 \n",
      "\n",
      "Epoch 743\n",
      "-------------------------------\n",
      "Train loss: 9.466166 \n",
      "\n",
      "Test loss: 7.238778 \n",
      "\n",
      "Epoch 744\n",
      "-------------------------------\n",
      "Train loss: 9.461179 \n",
      "\n",
      "Test loss: 7.228161 \n",
      "\n",
      "Epoch 745\n",
      "-------------------------------\n",
      "Train loss: 9.458687 \n",
      "\n",
      "Test loss: 7.227595 \n",
      "\n",
      "Epoch 746\n",
      "-------------------------------\n",
      "Train loss: 9.455916 \n",
      "\n",
      "Test loss: 7.229446 \n",
      "\n",
      "Epoch 747\n",
      "-------------------------------\n",
      "Train loss: 9.453402 \n",
      "\n",
      "Test loss: 7.223805 \n",
      "\n",
      "Epoch 748\n",
      "-------------------------------\n",
      "Train loss: 9.449562 \n",
      "\n",
      "Test loss: 7.217207 \n",
      "\n",
      "Epoch 749\n",
      "-------------------------------\n",
      "Train loss: 9.445520 \n",
      "\n",
      "Test loss: 7.218028 \n",
      "\n",
      "Epoch 750\n",
      "-------------------------------\n",
      "Train loss: 9.442093 \n",
      "\n",
      "Test loss: 7.198094 \n",
      "\n",
      "Epoch 751\n",
      "-------------------------------\n",
      "Train loss: 9.437279 \n",
      "\n",
      "Test loss: 7.208378 \n",
      "\n",
      "Epoch 752\n",
      "-------------------------------\n",
      "Train loss: 9.435962 \n",
      "\n",
      "Test loss: 7.204038 \n",
      "\n",
      "Epoch 753\n",
      "-------------------------------\n",
      "Train loss: 9.432898 \n",
      "\n",
      "Test loss: 7.200233 \n",
      "\n",
      "Epoch 754\n",
      "-------------------------------\n",
      "Train loss: 9.427602 \n",
      "\n",
      "Test loss: 7.197922 \n",
      "\n",
      "Epoch 755\n",
      "-------------------------------\n",
      "Train loss: 9.425593 \n",
      "\n",
      "Test loss: 7.201697 \n",
      "\n",
      "Epoch 756\n",
      "-------------------------------\n",
      "Train loss: 9.424007 \n",
      "\n",
      "Test loss: 7.198252 \n",
      "\n",
      "Epoch 757\n",
      "-------------------------------\n",
      "Train loss: 9.420996 \n",
      "\n",
      "Test loss: 7.197896 \n",
      "\n",
      "Epoch 758\n",
      "-------------------------------\n",
      "Train loss: 9.417701 \n",
      "\n",
      "Test loss: 7.194299 \n",
      "\n",
      "Epoch 759\n",
      "-------------------------------\n",
      "Train loss: 9.414879 \n",
      "\n",
      "Test loss: 7.195206 \n",
      "\n",
      "Epoch 760\n",
      "-------------------------------\n",
      "Train loss: 9.412173 \n",
      "\n",
      "Test loss: 7.193024 \n",
      "\n",
      "Epoch 761\n",
      "-------------------------------\n",
      "Train loss: 9.409652 \n",
      "\n",
      "Test loss: 7.188821 \n",
      "\n",
      "Epoch 762\n",
      "-------------------------------\n",
      "Train loss: 9.406862 \n",
      "\n",
      "Test loss: 7.186732 \n",
      "\n",
      "Epoch 763\n",
      "-------------------------------\n",
      "Train loss: 9.404101 \n",
      "\n",
      "Test loss: 7.187408 \n",
      "\n",
      "Epoch 764\n",
      "-------------------------------\n",
      "Train loss: 9.402042 \n",
      "\n",
      "Test loss: 7.186948 \n",
      "\n",
      "Epoch 765\n",
      "-------------------------------\n",
      "Train loss: 9.399519 \n",
      "\n",
      "Test loss: 7.183864 \n",
      "\n",
      "Epoch 766\n",
      "-------------------------------\n",
      "Train loss: 9.396296 \n",
      "\n",
      "Test loss: 7.180922 \n",
      "\n",
      "Epoch 767\n",
      "-------------------------------\n",
      "Train loss: 9.393473 \n",
      "\n",
      "Test loss: 7.179876 \n",
      "\n",
      "Epoch 768\n",
      "-------------------------------\n",
      "Train loss: 9.391317 \n",
      "\n",
      "Test loss: 7.180739 \n",
      "\n",
      "Epoch 769\n",
      "-------------------------------\n",
      "Train loss: 9.389650 \n",
      "\n",
      "Test loss: 7.179010 \n",
      "\n",
      "Epoch 770\n",
      "-------------------------------\n",
      "Train loss: 9.386281 \n",
      "\n",
      "Test loss: 7.176391 \n",
      "\n",
      "Epoch 771\n",
      "-------------------------------\n",
      "Train loss: 9.383080 \n",
      "\n",
      "Test loss: 7.175449 \n",
      "\n",
      "Epoch 772\n",
      "-------------------------------\n",
      "Train loss: 9.381004 \n",
      "\n",
      "Test loss: 7.174980 \n",
      "\n",
      "Epoch 773\n",
      "-------------------------------\n",
      "Train loss: 9.378977 \n",
      "\n",
      "Test loss: 7.173454 \n",
      "\n",
      "Epoch 774\n",
      "-------------------------------\n",
      "Train loss: 9.376297 \n",
      "\n",
      "Test loss: 7.171451 \n",
      "\n",
      "Epoch 775\n",
      "-------------------------------\n",
      "Train loss: 9.373530 \n",
      "\n",
      "Test loss: 7.169971 \n",
      "\n",
      "Epoch 776\n",
      "-------------------------------\n",
      "Train loss: 9.370574 \n",
      "\n",
      "Test loss: 7.162620 \n",
      "\n",
      "Epoch 777\n",
      "-------------------------------\n",
      "Train loss: 9.368483 \n",
      "\n",
      "Test loss: 7.161242 \n",
      "\n",
      "Epoch 778\n",
      "-------------------------------\n",
      "Train loss: 9.366693 \n",
      "\n",
      "Test loss: 7.168531 \n",
      "\n",
      "Epoch 779\n",
      "-------------------------------\n",
      "Train loss: 9.364879 \n",
      "\n",
      "Test loss: 7.167218 \n",
      "\n",
      "Epoch 780\n",
      "-------------------------------\n",
      "Train loss: 9.363125 \n",
      "\n",
      "Test loss: 7.160997 \n",
      "\n",
      "Epoch 781\n",
      "-------------------------------\n",
      "Train loss: 9.359029 \n",
      "\n",
      "Test loss: 7.162147 \n",
      "\n",
      "Epoch 782\n",
      "-------------------------------\n",
      "Train loss: 9.355798 \n",
      "\n",
      "Test loss: 7.161335 \n",
      "\n",
      "Epoch 783\n",
      "-------------------------------\n",
      "Train loss: 9.355197 \n",
      "\n",
      "Test loss: 7.160672 \n",
      "\n",
      "Epoch 784\n",
      "-------------------------------\n",
      "Train loss: 9.352902 \n",
      "\n",
      "Test loss: 7.156630 \n",
      "\n",
      "Epoch 785\n",
      "-------------------------------\n",
      "Train loss: 9.350048 \n",
      "\n",
      "Test loss: 7.158235 \n",
      "\n",
      "Epoch 786\n",
      "-------------------------------\n",
      "Train loss: 9.347816 \n",
      "\n",
      "Test loss: 7.157706 \n",
      "\n",
      "Epoch 787\n",
      "-------------------------------\n",
      "Train loss: 9.346286 \n",
      "\n",
      "Test loss: 7.158042 \n",
      "\n",
      "Epoch 788\n",
      "-------------------------------\n",
      "Train loss: 9.343738 \n",
      "\n",
      "Test loss: 7.155516 \n",
      "\n",
      "Epoch 789\n",
      "-------------------------------\n",
      "Train loss: 9.341677 \n",
      "\n",
      "Test loss: 7.155849 \n",
      "\n",
      "Epoch 790\n",
      "-------------------------------\n",
      "Train loss: 9.338890 \n",
      "\n",
      "Test loss: 7.154001 \n",
      "\n",
      "Epoch 791\n",
      "-------------------------------\n",
      "Train loss: 9.336245 \n",
      "\n",
      "Test loss: 7.149076 \n",
      "\n",
      "Epoch 792\n",
      "-------------------------------\n",
      "Train loss: 9.334884 \n",
      "\n",
      "Test loss: 7.153636 \n",
      "\n",
      "Epoch 793\n",
      "-------------------------------\n",
      "Train loss: 9.333073 \n",
      "\n",
      "Test loss: 7.156479 \n",
      "\n",
      "Epoch 794\n",
      "-------------------------------\n",
      "Train loss: 9.331080 \n",
      "\n",
      "Test loss: 7.149509 \n",
      "\n",
      "Epoch 795\n",
      "-------------------------------\n",
      "Train loss: 9.328582 \n",
      "\n",
      "Test loss: 7.150752 \n",
      "\n",
      "Epoch 796\n",
      "-------------------------------\n",
      "Train loss: 9.326151 \n",
      "\n",
      "Test loss: 7.152757 \n",
      "\n",
      "Epoch 797\n",
      "-------------------------------\n",
      "Train loss: 9.324069 \n",
      "\n",
      "Test loss: 7.148436 \n",
      "\n",
      "Epoch 798\n",
      "-------------------------------\n",
      "Train loss: 9.322451 \n",
      "\n",
      "Test loss: 7.150642 \n",
      "\n",
      "Epoch 799\n",
      "-------------------------------\n",
      "Train loss: 9.319990 \n",
      "\n",
      "Test loss: 7.151871 \n",
      "\n",
      "Epoch 800\n",
      "-------------------------------\n",
      "Train loss: 9.317890 \n",
      "\n",
      "Test loss: 7.145996 \n",
      "\n",
      "Epoch 801\n",
      "-------------------------------\n",
      "Train loss: 9.316125 \n",
      "\n",
      "Test loss: 7.149072 \n",
      "\n",
      "Epoch 802\n",
      "-------------------------------\n",
      "Train loss: 9.314264 \n",
      "\n",
      "Test loss: 7.150909 \n",
      "\n",
      "Epoch 803\n",
      "-------------------------------\n",
      "Train loss: 9.311913 \n",
      "\n",
      "Test loss: 7.144998 \n",
      "\n",
      "Epoch 804\n",
      "-------------------------------\n",
      "Train loss: 9.309799 \n",
      "\n",
      "Test loss: 7.146827 \n",
      "\n",
      "Epoch 805\n",
      "-------------------------------\n",
      "Train loss: 9.307496 \n",
      "\n",
      "Test loss: 7.150352 \n",
      "\n",
      "Epoch 806\n",
      "-------------------------------\n",
      "Train loss: 9.306423 \n",
      "\n",
      "Test loss: 7.144962 \n",
      "\n",
      "Epoch 807\n",
      "-------------------------------\n",
      "Train loss: 9.303782 \n",
      "\n",
      "Test loss: 7.138629 \n",
      "\n",
      "Epoch 808\n",
      "-------------------------------\n",
      "Train loss: 9.301151 \n",
      "\n",
      "Test loss: 7.147746 \n",
      "\n",
      "Epoch 809\n",
      "-------------------------------\n",
      "Train loss: 9.300416 \n",
      "\n",
      "Test loss: 7.154886 \n",
      "\n",
      "Epoch 810\n",
      "-------------------------------\n",
      "Train loss: 9.300032 \n",
      "\n",
      "Test loss: 7.144631 \n",
      "\n",
      "Epoch 811\n",
      "-------------------------------\n",
      "Train loss: 9.295771 \n",
      "\n",
      "Test loss: 7.133391 \n",
      "\n",
      "Epoch 812\n",
      "-------------------------------\n",
      "Train loss: 9.291953 \n",
      "\n",
      "Test loss: 7.144246 \n",
      "\n",
      "Epoch 813\n",
      "-------------------------------\n",
      "Train loss: 9.292267 \n",
      "\n",
      "Test loss: 7.155954 \n",
      "\n",
      "Epoch 814\n",
      "-------------------------------\n",
      "Train loss: 9.293469 \n",
      "\n",
      "Test loss: 7.146120 \n",
      "\n",
      "Epoch 815\n",
      "-------------------------------\n",
      "Train loss: 9.289025 \n",
      "\n",
      "Test loss: 7.131583 \n",
      "\n",
      "Epoch 816\n",
      "-------------------------------\n",
      "Train loss: 9.283869 \n",
      "\n",
      "Test loss: 7.142237 \n",
      "\n",
      "Epoch 817\n",
      "-------------------------------\n",
      "Train loss: 9.284395 \n",
      "\n",
      "Test loss: 7.154163 \n",
      "\n",
      "Epoch 818\n",
      "-------------------------------\n",
      "Train loss: 9.285449 \n",
      "\n",
      "Test loss: 7.145652 \n",
      "\n",
      "Epoch 819\n",
      "-------------------------------\n",
      "Train loss: 9.281781 \n",
      "\n",
      "Test loss: 7.131600 \n",
      "\n",
      "Epoch 820\n",
      "-------------------------------\n",
      "Train loss: 9.276426 \n",
      "\n",
      "Test loss: 7.133514 \n",
      "\n",
      "Epoch 821\n",
      "-------------------------------\n",
      "Train loss: 9.276105 \n",
      "\n",
      "Test loss: 7.144632 \n",
      "\n",
      "Epoch 822\n",
      "-------------------------------\n",
      "Train loss: 9.277688 \n",
      "\n",
      "Test loss: 7.147934 \n",
      "\n",
      "Epoch 823\n",
      "-------------------------------\n",
      "Train loss: 9.276181 \n",
      "\n",
      "Test loss: 7.142120 \n",
      "\n",
      "Epoch 824\n",
      "-------------------------------\n",
      "Train loss: 9.272122 \n",
      "\n",
      "Test loss: 7.135924 \n",
      "\n",
      "Epoch 825\n",
      "-------------------------------\n",
      "Train loss: 9.268313 \n",
      "\n",
      "Test loss: 7.137404 \n",
      "\n",
      "Epoch 826\n",
      "-------------------------------\n",
      "Train loss: 9.267633 \n",
      "\n",
      "Test loss: 7.144333 \n",
      "\n",
      "Epoch 827\n",
      "-------------------------------\n",
      "Train loss: 9.268586 \n",
      "\n",
      "Test loss: 7.145428 \n",
      "\n",
      "Epoch 828\n",
      "-------------------------------\n",
      "Train loss: 9.266545 \n",
      "\n",
      "Test loss: 7.140593 \n",
      "\n",
      "Epoch 829\n",
      "-------------------------------\n",
      "Train loss: 9.262770 \n",
      "\n",
      "Test loss: 7.138912 \n",
      "\n",
      "Epoch 830\n",
      "-------------------------------\n",
      "Train loss: 9.260857 \n",
      "\n",
      "Test loss: 7.140639 \n",
      "\n",
      "Epoch 831\n",
      "-------------------------------\n",
      "Train loss: 9.259879 \n",
      "\n",
      "Test loss: 7.144066 \n",
      "\n",
      "Epoch 832\n",
      "-------------------------------\n",
      "Train loss: 9.259413 \n",
      "\n",
      "Test loss: 7.143719 \n",
      "\n",
      "Epoch 833\n",
      "-------------------------------\n",
      "Train loss: 9.257068 \n",
      "\n",
      "Test loss: 7.140892 \n",
      "\n",
      "Epoch 834\n",
      "-------------------------------\n",
      "Train loss: 9.254276 \n",
      "\n",
      "Test loss: 7.141183 \n",
      "\n",
      "Epoch 835\n",
      "-------------------------------\n",
      "Train loss: 9.253107 \n",
      "\n",
      "Test loss: 7.142321 \n",
      "\n",
      "Epoch 836\n",
      "-------------------------------\n",
      "Train loss: 9.251790 \n",
      "\n",
      "Test loss: 7.143998 \n",
      "\n",
      "Epoch 837\n",
      "-------------------------------\n",
      "Train loss: 9.250715 \n",
      "\n",
      "Test loss: 7.143161 \n",
      "\n",
      "Epoch 838\n",
      "-------------------------------\n",
      "Train loss: 9.248374 \n",
      "\n",
      "Test loss: 7.141328 \n",
      "\n",
      "Epoch 839\n",
      "-------------------------------\n",
      "Train loss: 9.246132 \n",
      "\n",
      "Test loss: 7.142378 \n",
      "\n",
      "Epoch 840\n",
      "-------------------------------\n",
      "Train loss: 9.245227 \n",
      "\n",
      "Test loss: 7.144683 \n",
      "\n",
      "Epoch 841\n",
      "-------------------------------\n",
      "Train loss: 9.244330 \n",
      "\n",
      "Test loss: 7.144248 \n",
      "\n",
      "Epoch 842\n",
      "-------------------------------\n",
      "Train loss: 9.241995 \n",
      "\n",
      "Test loss: 7.142437 \n",
      "\n",
      "Epoch 843\n",
      "-------------------------------\n",
      "Train loss: 9.239816 \n",
      "\n",
      "Test loss: 7.146146 \n",
      "\n",
      "Epoch 844\n",
      "-------------------------------\n",
      "Train loss: 9.239195 \n",
      "\n",
      "Test loss: 7.149491 \n",
      "\n",
      "Epoch 845\n",
      "-------------------------------\n",
      "Train loss: 9.237809 \n",
      "\n",
      "Test loss: 7.148980 \n",
      "\n",
      "Epoch 846\n",
      "-------------------------------\n",
      "Train loss: 9.235949 \n",
      "\n",
      "Test loss: 7.144426 \n",
      "\n",
      "Epoch 847\n",
      "-------------------------------\n",
      "Train loss: 9.232917 \n",
      "\n",
      "Test loss: 7.143408 \n",
      "\n",
      "Epoch 848\n",
      "-------------------------------\n",
      "Train loss: 9.231420 \n",
      "\n",
      "Test loss: 7.145237 \n",
      "\n",
      "Epoch 849\n",
      "-------------------------------\n",
      "Train loss: 9.230458 \n",
      "\n",
      "Test loss: 7.148060 \n",
      "\n",
      "Epoch 850\n",
      "-------------------------------\n",
      "Train loss: 9.229912 \n",
      "\n",
      "Test loss: 7.146942 \n",
      "\n",
      "Epoch 851\n",
      "-------------------------------\n",
      "Train loss: 9.227707 \n",
      "\n",
      "Test loss: 7.145285 \n",
      "\n",
      "Epoch 852\n",
      "-------------------------------\n",
      "Train loss: 9.225657 \n",
      "\n",
      "Test loss: 7.144098 \n",
      "\n",
      "Epoch 853\n",
      "-------------------------------\n",
      "Train loss: 9.223646 \n",
      "\n",
      "Test loss: 7.145887 \n",
      "\n",
      "Epoch 854\n",
      "-------------------------------\n",
      "Train loss: 9.222919 \n",
      "\n",
      "Test loss: 7.148365 \n",
      "\n",
      "Epoch 855\n",
      "-------------------------------\n",
      "Train loss: 9.222100 \n",
      "\n",
      "Test loss: 7.147375 \n",
      "\n",
      "Epoch 856\n",
      "-------------------------------\n",
      "Train loss: 9.219739 \n",
      "\n",
      "Test loss: 7.145033 \n",
      "\n",
      "Epoch 857\n",
      "-------------------------------\n",
      "Train loss: 9.217404 \n",
      "\n",
      "Test loss: 7.145965 \n",
      "\n",
      "Epoch 858\n",
      "-------------------------------\n",
      "Train loss: 9.216620 \n",
      "\n",
      "Test loss: 7.146828 \n",
      "\n",
      "Epoch 859\n",
      "-------------------------------\n",
      "Train loss: 9.215425 \n",
      "\n",
      "Test loss: 7.147843 \n",
      "\n",
      "Epoch 860\n",
      "-------------------------------\n",
      "Train loss: 9.214331 \n",
      "\n",
      "Test loss: 7.148464 \n",
      "\n",
      "Epoch 861\n",
      "-------------------------------\n",
      "Train loss: 9.212783 \n",
      "\n",
      "Test loss: 7.147117 \n",
      "\n",
      "Epoch 862\n",
      "-------------------------------\n",
      "Train loss: 9.210363 \n",
      "\n",
      "Test loss: 7.145986 \n",
      "\n",
      "Epoch 863\n",
      "-------------------------------\n",
      "Train loss: 9.208578 \n",
      "\n",
      "Test loss: 7.147840 \n",
      "\n",
      "Epoch 864\n",
      "-------------------------------\n",
      "Train loss: 9.208159 \n",
      "\n",
      "Test loss: 7.150338 \n",
      "\n",
      "Epoch 865\n",
      "-------------------------------\n",
      "Train loss: 9.207447 \n",
      "\n",
      "Test loss: 7.149520 \n",
      "\n",
      "Epoch 866\n",
      "-------------------------------\n",
      "Train loss: 9.205168 \n",
      "\n",
      "Test loss: 7.147324 \n",
      "\n",
      "Epoch 867\n",
      "-------------------------------\n",
      "Train loss: 9.202941 \n",
      "\n",
      "Test loss: 7.148182 \n",
      "\n",
      "Epoch 868\n",
      "-------------------------------\n",
      "Train loss: 9.202147 \n",
      "\n",
      "Test loss: 7.150882 \n",
      "\n",
      "Epoch 869\n",
      "-------------------------------\n",
      "Train loss: 9.201547 \n",
      "\n",
      "Test loss: 7.152726 \n",
      "\n",
      "Epoch 870\n",
      "-------------------------------\n",
      "Train loss: 9.200299 \n",
      "\n",
      "Test loss: 7.151444 \n",
      "\n",
      "Epoch 871\n",
      "-------------------------------\n",
      "Train loss: 9.197794 \n",
      "\n",
      "Test loss: 7.149703 \n",
      "\n",
      "Epoch 872\n",
      "-------------------------------\n",
      "Train loss: 9.195767 \n",
      "\n",
      "Test loss: 7.151373 \n",
      "\n",
      "Epoch 873\n",
      "-------------------------------\n",
      "Train loss: 9.195347 \n",
      "\n",
      "Test loss: 7.154366 \n",
      "\n",
      "Epoch 874\n",
      "-------------------------------\n",
      "Train loss: 9.194905 \n",
      "\n",
      "Test loss: 7.154168 \n",
      "\n",
      "Epoch 875\n",
      "-------------------------------\n",
      "Train loss: 9.192918 \n",
      "\n",
      "Test loss: 7.152050 \n",
      "\n",
      "Epoch 876\n",
      "-------------------------------\n",
      "Train loss: 9.190764 \n",
      "\n",
      "Test loss: 7.152543 \n",
      "\n",
      "Epoch 877\n",
      "-------------------------------\n",
      "Train loss: 9.189878 \n",
      "\n",
      "Test loss: 7.155044 \n",
      "\n",
      "Epoch 878\n",
      "-------------------------------\n",
      "Train loss: 9.189269 \n",
      "\n",
      "Test loss: 7.157141 \n",
      "\n",
      "Epoch 879\n",
      "-------------------------------\n",
      "Train loss: 9.188149 \n",
      "\n",
      "Test loss: 7.156251 \n",
      "\n",
      "Epoch 880\n",
      "-------------------------------\n",
      "Train loss: 9.185857 \n",
      "\n",
      "Test loss: 7.154548 \n",
      "\n",
      "Epoch 881\n",
      "-------------------------------\n",
      "Train loss: 9.183947 \n",
      "\n",
      "Test loss: 7.155995 \n",
      "\n",
      "Epoch 882\n",
      "-------------------------------\n",
      "Train loss: 9.183475 \n",
      "\n",
      "Test loss: 7.158948 \n",
      "\n",
      "Epoch 883\n",
      "-------------------------------\n",
      "Train loss: 9.183031 \n",
      "\n",
      "Test loss: 7.160785 \n",
      "\n",
      "Epoch 884\n",
      "-------------------------------\n",
      "Train loss: 9.181821 \n",
      "\n",
      "Test loss: 7.159431 \n",
      "\n",
      "Epoch 885\n",
      "-------------------------------\n",
      "Train loss: 9.179374 \n",
      "\n",
      "Test loss: 7.157614 \n",
      "\n",
      "Epoch 886\n",
      "-------------------------------\n",
      "Train loss: 9.177484 \n",
      "\n",
      "Test loss: 7.159259 \n",
      "\n",
      "Epoch 887\n",
      "-------------------------------\n",
      "Train loss: 9.177149 \n",
      "\n",
      "Test loss: 7.162471 \n",
      "\n",
      "Epoch 888\n",
      "-------------------------------\n",
      "Train loss: 9.176846 \n",
      "\n",
      "Test loss: 7.164333 \n",
      "\n",
      "Epoch 889\n",
      "-------------------------------\n",
      "Train loss: 9.175644 \n",
      "\n",
      "Test loss: 7.162846 \n",
      "\n",
      "Epoch 890\n",
      "-------------------------------\n",
      "Train loss: 9.173227 \n",
      "\n",
      "Test loss: 7.162695 \n",
      "\n",
      "Epoch 891\n",
      "-------------------------------\n",
      "Train loss: 9.171843 \n",
      "\n",
      "Test loss: 7.164896 \n",
      "\n",
      "Epoch 892\n",
      "-------------------------------\n",
      "Train loss: 9.171191 \n",
      "\n",
      "Test loss: 7.165830 \n",
      "\n",
      "Epoch 893\n",
      "-------------------------------\n",
      "Train loss: 9.169974 \n",
      "\n",
      "Test loss: 7.166904 \n",
      "\n",
      "Epoch 894\n",
      "-------------------------------\n",
      "Train loss: 9.169148 \n",
      "\n",
      "Test loss: 7.168031 \n",
      "\n",
      "Epoch 895\n",
      "-------------------------------\n",
      "Train loss: 9.167996 \n",
      "\n",
      "Test loss: 7.167230 \n",
      "\n",
      "Epoch 896\n",
      "-------------------------------\n",
      "Train loss: 9.166074 \n",
      "\n",
      "Test loss: 7.167841 \n",
      "\n",
      "Epoch 897\n",
      "-------------------------------\n",
      "Train loss: 9.165058 \n",
      "\n",
      "Test loss: 7.169938 \n",
      "\n",
      "Epoch 898\n",
      "-------------------------------\n",
      "Train loss: 9.164334 \n",
      "\n",
      "Test loss: 7.172003 \n",
      "\n",
      "Epoch 899\n",
      "-------------------------------\n",
      "Train loss: 9.163420 \n",
      "\n",
      "Test loss: 7.171493 \n",
      "\n",
      "Epoch 900\n",
      "-------------------------------\n",
      "Train loss: 9.161588 \n",
      "\n",
      "Test loss: 7.171826 \n",
      "\n",
      "Epoch 901\n",
      "-------------------------------\n",
      "Train loss: 9.160551 \n",
      "\n",
      "Test loss: 7.173510 \n",
      "\n",
      "Epoch 902\n",
      "-------------------------------\n",
      "Train loss: 9.159754 \n",
      "\n",
      "Test loss: 7.175394 \n",
      "\n",
      "Epoch 903\n",
      "-------------------------------\n",
      "Train loss: 9.158859 \n",
      "\n",
      "Test loss: 7.174903 \n",
      "\n",
      "Epoch 904\n",
      "-------------------------------\n",
      "Train loss: 9.157122 \n",
      "\n",
      "Test loss: 7.175164 \n",
      "\n",
      "Epoch 905\n",
      "-------------------------------\n",
      "Train loss: 9.156109 \n",
      "\n",
      "Test loss: 7.176678 \n",
      "\n",
      "Epoch 906\n",
      "-------------------------------\n",
      "Train loss: 9.155267 \n",
      "\n",
      "Test loss: 7.178529 \n",
      "\n",
      "Epoch 907\n",
      "-------------------------------\n",
      "Train loss: 9.154332 \n",
      "\n",
      "Test loss: 7.179999 \n",
      "\n",
      "Epoch 908\n",
      "-------------------------------\n",
      "Train loss: 9.153229 \n",
      "\n",
      "Test loss: 7.179281 \n",
      "\n",
      "Epoch 909\n",
      "-------------------------------\n",
      "Train loss: 9.151434 \n",
      "\n",
      "Test loss: 7.179773 \n",
      "\n",
      "Epoch 910\n",
      "-------------------------------\n",
      "Train loss: 9.150560 \n",
      "\n",
      "Test loss: 7.181670 \n",
      "\n",
      "Epoch 911\n",
      "-------------------------------\n",
      "Train loss: 9.149908 \n",
      "\n",
      "Test loss: 7.183639 \n",
      "\n",
      "Epoch 912\n",
      "-------------------------------\n",
      "Train loss: 9.149055 \n",
      "\n",
      "Test loss: 7.184961 \n",
      "\n",
      "Epoch 913\n",
      "-------------------------------\n",
      "Train loss: 9.147916 \n",
      "\n",
      "Test loss: 7.184001 \n",
      "\n",
      "Epoch 914\n",
      "-------------------------------\n",
      "Train loss: 9.146082 \n",
      "\n",
      "Test loss: 7.184376 \n",
      "\n",
      "Epoch 915\n",
      "-------------------------------\n",
      "Train loss: 9.145227 \n",
      "\n",
      "Test loss: 7.186344 \n",
      "\n",
      "Epoch 916\n",
      "-------------------------------\n",
      "Train loss: 9.144638 \n",
      "\n",
      "Test loss: 7.188389 \n",
      "\n",
      "Epoch 917\n",
      "-------------------------------\n",
      "Train loss: 9.143870 \n",
      "\n",
      "Test loss: 7.189714 \n",
      "\n",
      "Epoch 918\n",
      "-------------------------------\n",
      "Train loss: 9.142762 \n",
      "\n",
      "Test loss: 7.190562 \n",
      "\n",
      "Epoch 919\n",
      "-------------------------------\n",
      "Train loss: 9.141472 \n",
      "\n",
      "Test loss: 7.189712 \n",
      "\n",
      "Epoch 920\n",
      "-------------------------------\n",
      "Train loss: 9.139785 \n",
      "\n",
      "Test loss: 7.190502 \n",
      "\n",
      "Epoch 921\n",
      "-------------------------------\n",
      "Train loss: 9.139145 \n",
      "\n",
      "Test loss: 7.192663 \n",
      "\n",
      "Epoch 922\n",
      "-------------------------------\n",
      "Train loss: 9.138677 \n",
      "\n",
      "Test loss: 7.194523 \n",
      "\n",
      "Epoch 923\n",
      "-------------------------------\n",
      "Train loss: 9.137859 \n",
      "\n",
      "Test loss: 7.195621 \n",
      "\n",
      "Epoch 924\n",
      "-------------------------------\n",
      "Train loss: 9.136657 \n",
      "\n",
      "Test loss: 7.196463 \n",
      "\n",
      "Epoch 925\n",
      "-------------------------------\n",
      "Train loss: 9.135413 \n",
      "\n",
      "Test loss: 7.197711 \n",
      "\n",
      "Epoch 926\n",
      "-------------------------------\n",
      "Train loss: 9.134373 \n",
      "\n",
      "Test loss: 7.199315 \n",
      "\n",
      "Epoch 927\n",
      "-------------------------------\n",
      "Train loss: 9.133488 \n",
      "\n",
      "Test loss: 7.199001 \n",
      "\n",
      "Epoch 928\n",
      "-------------------------------\n",
      "Train loss: 9.132104 \n",
      "\n",
      "Test loss: 7.199581 \n",
      "\n",
      "Epoch 929\n",
      "-------------------------------\n",
      "Train loss: 9.131476 \n",
      "\n",
      "Test loss: 7.201182 \n",
      "\n",
      "Epoch 930\n",
      "-------------------------------\n",
      "Train loss: 9.130867 \n",
      "\n",
      "Test loss: 7.202815 \n",
      "\n",
      "Epoch 931\n",
      "-------------------------------\n",
      "Train loss: 9.130011 \n",
      "\n",
      "Test loss: 7.204016 \n",
      "\n",
      "Epoch 932\n",
      "-------------------------------\n",
      "Train loss: 9.128899 \n",
      "\n",
      "Test loss: 7.205024 \n",
      "\n",
      "Epoch 933\n",
      "-------------------------------\n",
      "Train loss: 9.127752 \n",
      "\n",
      "Test loss: 7.206263 \n",
      "\n",
      "Epoch 934\n",
      "-------------------------------\n",
      "Train loss: 9.126769 \n",
      "\n",
      "Test loss: 7.207807 \n",
      "\n",
      "Epoch 935\n",
      "-------------------------------\n",
      "Train loss: 9.125941 \n",
      "\n",
      "Test loss: 7.209417 \n",
      "\n",
      "Epoch 936\n",
      "-------------------------------\n",
      "Train loss: 9.125151 \n",
      "\n",
      "Test loss: 7.210767 \n",
      "\n",
      "Epoch 937\n",
      "-------------------------------\n",
      "Train loss: 9.124281 \n",
      "\n",
      "Test loss: 7.211887 \n",
      "\n",
      "Epoch 938\n",
      "-------------------------------\n",
      "Train loss: 9.123328 \n",
      "\n",
      "Test loss: 7.212921 \n",
      "\n",
      "Epoch 939\n",
      "-------------------------------\n",
      "Train loss: 9.122372 \n",
      "\n",
      "Test loss: 7.214023 \n",
      "\n",
      "Epoch 940\n",
      "-------------------------------\n",
      "Train loss: 9.121440 \n",
      "\n",
      "Test loss: 7.215160 \n",
      "\n",
      "Epoch 941\n",
      "-------------------------------\n",
      "Train loss: 9.120556 \n",
      "\n",
      "Test loss: 7.216295 \n",
      "\n",
      "Epoch 942\n",
      "-------------------------------\n",
      "Train loss: 9.119678 \n",
      "\n",
      "Test loss: 7.217408 \n",
      "\n",
      "Epoch 943\n",
      "-------------------------------\n",
      "Train loss: 9.118802 \n",
      "\n",
      "Test loss: 7.218486 \n",
      "\n",
      "Epoch 944\n",
      "-------------------------------\n",
      "Train loss: 9.117920 \n",
      "\n",
      "Test loss: 7.219565 \n",
      "\n",
      "Epoch 945\n",
      "-------------------------------\n",
      "Train loss: 9.117036 \n",
      "\n",
      "Test loss: 7.220623 \n",
      "\n",
      "Epoch 946\n",
      "-------------------------------\n",
      "Train loss: 9.116163 \n",
      "\n",
      "Test loss: 7.221709 \n",
      "\n",
      "Epoch 947\n",
      "-------------------------------\n",
      "Train loss: 9.115293 \n",
      "\n",
      "Test loss: 7.222743 \n",
      "\n",
      "Epoch 948\n",
      "-------------------------------\n",
      "Train loss: 9.113616 \n",
      "\n",
      "Test loss: 7.221407 \n",
      "\n",
      "Epoch 949\n",
      "-------------------------------\n",
      "Train loss: 9.112740 \n",
      "\n",
      "Test loss: 7.224358 \n",
      "\n",
      "Epoch 950\n",
      "-------------------------------\n",
      "Train loss: 9.112790 \n",
      "\n",
      "Test loss: 7.227459 \n",
      "\n",
      "Epoch 951\n",
      "-------------------------------\n",
      "Train loss: 9.111760 \n",
      "\n",
      "Test loss: 7.226451 \n",
      "\n",
      "Epoch 952\n",
      "-------------------------------\n",
      "Train loss: 9.110877 \n",
      "\n",
      "Test loss: 7.228198 \n",
      "\n",
      "Epoch 953\n",
      "-------------------------------\n",
      "Train loss: 9.110440 \n",
      "\n",
      "Test loss: 7.230112 \n",
      "\n",
      "Epoch 954\n",
      "-------------------------------\n",
      "Train loss: 9.109793 \n",
      "\n",
      "Test loss: 7.231442 \n",
      "\n",
      "Epoch 955\n",
      "-------------------------------\n",
      "Train loss: 9.108917 \n",
      "\n",
      "Test loss: 7.231900 \n",
      "\n",
      "Epoch 956\n",
      "-------------------------------\n",
      "Train loss: 9.107001 \n",
      "\n",
      "Test loss: 7.229886 \n",
      "\n",
      "Epoch 957\n",
      "-------------------------------\n",
      "Train loss: 9.105870 \n",
      "\n",
      "Test loss: 7.232789 \n",
      "\n",
      "Epoch 958\n",
      "-------------------------------\n",
      "Train loss: 9.105894 \n",
      "\n",
      "Test loss: 7.236418 \n",
      "\n",
      "Epoch 959\n",
      "-------------------------------\n",
      "Train loss: 9.105879 \n",
      "\n",
      "Test loss: 7.238459 \n",
      "\n",
      "Epoch 960\n",
      "-------------------------------\n",
      "Train loss: 9.104413 \n",
      "\n",
      "Test loss: 7.236211 \n",
      "\n",
      "Epoch 961\n",
      "-------------------------------\n",
      "Train loss: 9.103151 \n",
      "\n",
      "Test loss: 7.237900 \n",
      "\n",
      "Epoch 962\n",
      "-------------------------------\n",
      "Train loss: 9.102748 \n",
      "\n",
      "Test loss: 7.240794 \n",
      "\n",
      "Epoch 963\n",
      "-------------------------------\n",
      "Train loss: 9.102473 \n",
      "\n",
      "Test loss: 7.242858 \n",
      "\n",
      "Epoch 964\n",
      "-------------------------------\n",
      "Train loss: 9.101056 \n",
      "\n",
      "Test loss: 7.240906 \n",
      "\n",
      "Epoch 965\n",
      "-------------------------------\n",
      "Train loss: 9.099963 \n",
      "\n",
      "Test loss: 7.242776 \n",
      "\n",
      "Epoch 966\n",
      "-------------------------------\n",
      "Train loss: 9.099625 \n",
      "\n",
      "Test loss: 7.245742 \n",
      "\n",
      "Epoch 967\n",
      "-------------------------------\n",
      "Train loss: 9.099345 \n",
      "\n",
      "Test loss: 7.247870 \n",
      "\n",
      "Epoch 968\n",
      "-------------------------------\n",
      "Train loss: 9.097939 \n",
      "\n",
      "Test loss: 7.246017 \n",
      "\n",
      "Epoch 969\n",
      "-------------------------------\n",
      "Train loss: 9.096892 \n",
      "\n",
      "Test loss: 7.247908 \n",
      "\n",
      "Epoch 970\n",
      "-------------------------------\n",
      "Train loss: 9.096591 \n",
      "\n",
      "Test loss: 7.250801 \n",
      "\n",
      "Epoch 971\n",
      "-------------------------------\n",
      "Train loss: 9.096319 \n",
      "\n",
      "Test loss: 7.252853 \n",
      "\n",
      "Epoch 972\n",
      "-------------------------------\n",
      "Train loss: 9.094918 \n",
      "\n",
      "Test loss: 7.250905 \n",
      "\n",
      "Epoch 973\n",
      "-------------------------------\n",
      "Train loss: 9.093896 \n",
      "\n",
      "Test loss: 7.253638 \n",
      "\n",
      "Epoch 974\n",
      "-------------------------------\n",
      "Train loss: 9.093844 \n",
      "\n",
      "Test loss: 7.256868 \n",
      "\n",
      "Epoch 975\n",
      "-------------------------------\n",
      "Train loss: 9.093478 \n",
      "\n",
      "Test loss: 7.258628 \n",
      "\n",
      "Epoch 976\n",
      "-------------------------------\n",
      "Train loss: 9.111222 \n",
      "\n",
      "Test loss: 7.407752 \n",
      "\n",
      "Epoch 977\n",
      "-------------------------------\n",
      "Train loss: 9.137296 \n",
      "\n",
      "Test loss: 7.539511 \n",
      "\n",
      "Epoch 978\n",
      "-------------------------------\n",
      "Train loss: 9.151812 \n",
      "\n",
      "Test loss: 7.468162 \n",
      "\n",
      "Epoch 979\n",
      "-------------------------------\n",
      "Train loss: 9.125772 \n",
      "\n",
      "Test loss: 7.315696 \n",
      "\n",
      "Epoch 980\n",
      "-------------------------------\n",
      "Train loss: 9.078678 \n",
      "\n",
      "Test loss: 7.248427 \n",
      "\n",
      "Epoch 981\n",
      "-------------------------------\n",
      "Train loss: 9.045627 \n",
      "\n",
      "Test loss: 7.279111 \n",
      "\n",
      "Epoch 982\n",
      "-------------------------------\n",
      "Train loss: 9.037948 \n",
      "\n",
      "Test loss: 7.257878 \n",
      "\n",
      "Epoch 983\n",
      "-------------------------------\n",
      "Train loss: 9.038382 \n",
      "\n",
      "Test loss: 7.223262 \n",
      "\n",
      "Epoch 984\n",
      "-------------------------------\n",
      "Train loss: 9.038982 \n",
      "\n",
      "Test loss: 7.230958 \n",
      "\n",
      "Epoch 985\n",
      "-------------------------------\n",
      "Train loss: 9.040067 \n",
      "\n",
      "Test loss: 7.269111 \n",
      "\n",
      "Epoch 986\n",
      "-------------------------------\n",
      "Train loss: 9.044032 \n",
      "\n",
      "Test loss: 7.275522 \n",
      "\n",
      "Epoch 987\n",
      "-------------------------------\n",
      "Train loss: 9.042101 \n",
      "\n",
      "Test loss: 7.247129 \n",
      "\n",
      "Epoch 988\n",
      "-------------------------------\n",
      "Train loss: 9.032869 \n",
      "\n",
      "Test loss: 7.225502 \n",
      "\n",
      "Epoch 989\n",
      "-------------------------------\n",
      "Train loss: 9.024024 \n",
      "\n",
      "Test loss: 7.228419 \n",
      "\n",
      "Epoch 990\n",
      "-------------------------------\n",
      "Train loss: 9.020939 \n",
      "\n",
      "Test loss: 7.238438 \n",
      "\n",
      "Epoch 991\n",
      "-------------------------------\n",
      "Train loss: 9.021120 \n",
      "\n",
      "Test loss: 7.239588 \n",
      "\n",
      "Epoch 992\n",
      "-------------------------------\n",
      "Train loss: 9.020589 \n",
      "\n",
      "Test loss: 7.236390 \n",
      "\n",
      "Epoch 993\n",
      "-------------------------------\n",
      "Train loss: 9.018538 \n",
      "\n",
      "Test loss: 7.236410 \n",
      "\n",
      "Epoch 994\n",
      "-------------------------------\n",
      "Train loss: 9.015692 \n",
      "\n",
      "Test loss: 7.237371 \n",
      "\n",
      "Epoch 995\n",
      "-------------------------------\n",
      "Train loss: 9.011572 \n",
      "\n",
      "Test loss: 7.230972 \n",
      "\n",
      "Epoch 996\n",
      "-------------------------------\n",
      "Train loss: 9.005944 \n",
      "\n",
      "Test loss: 7.249745 \n",
      "\n",
      "Epoch 997\n",
      "-------------------------------\n",
      "Train loss: 9.006841 \n",
      "\n",
      "Test loss: 7.261039 \n",
      "\n",
      "Epoch 998\n",
      "-------------------------------\n",
      "Train loss: 9.008897 \n",
      "\n",
      "Test loss: 7.255659 \n",
      "\n",
      "Epoch 999\n",
      "-------------------------------\n",
      "Train loss: 9.006195 \n",
      "\n",
      "Test loss: 7.246102 \n",
      "\n",
      "Epoch 1000\n",
      "-------------------------------\n",
      "Train loss: 9.000434 \n",
      "\n",
      "Test loss: 7.242764 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    \n",
    "    model = VanillaNetwork()\n",
    "    loss_fn = nn.MSELoss() # objective\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    batch_size = 64\n",
    "    \n",
    "    train_dl, test_dl = loaddata(batch_size)\n",
    "\n",
    "    epochs = 1000\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        print(f\"Epoch {e+1}\\n-------------------------------\")\n",
    "        train_loss = train(train_dl, model, loss_fn, optimizer)\n",
    "        test_loss = test(test_dl, model, loss_fn)\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(range(epochs), train_losses)\n",
    "    plt.plot(range(epochs), test_losses)\n",
    "    plt.legend(['train', 'test'])\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
